{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "RANDOM = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikus_train_df = pd.read_pickle('./data/haikus_train_df.pickle')\n",
    "haikus_test_df = pd.read_pickle('./data/haikus_test_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN letter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1849446\n",
      "Total Vocab:  107\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = ''.join(haikus_train_df['textchar_withtokens'])\n",
    "\n",
    "chars = sorted(set(list(corpus_raw)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(corpus_raw)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int[''] = n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = chars + ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poems = len(haikus_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max patterns per poem:  801\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length_char = 150\n",
    "\n",
    "poemX = []\n",
    "poemY = []\n",
    "n_patterns = 0\n",
    "\n",
    "for poem_index in range(0, n_poems):\n",
    "\n",
    "    textX = []\n",
    "    textY = []\n",
    "    poem = haikus_train_df['textchar_withtokens'].iloc[poem_index]\n",
    "    # add padding to poem\n",
    "    poem = list(np.full(seq_length_char - 1, '')) + list(poem)\n",
    "    for i in range(0,  len(poem) - seq_length_char, 1):\n",
    "        seq_in = poem[i:i + seq_length_char]\n",
    "        seq_out = poem[i + seq_length_char]\n",
    "        textX.append([char_to_int[char] for char in seq_in])\n",
    "        textY.append(char_to_int[seq_out])\n",
    "    n_patterns = max(n_patterns, len(textX))\n",
    "    \n",
    "    poemX.append(textX)\n",
    "    poemY.append(textY)\n",
    "\n",
    "print(\"Max patterns per poem: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoem_charindex = char_to_int['◘']\n",
    "newline_charindex = char_to_int['↕']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(haikus_train_df['textchar_withtokens'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoem_charindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poemchar(index):\n",
    "    char = int_to_char[index]\n",
    "    if char == '↕':\n",
    "        char = '\\n'\n",
    "    #elif char == '◘':\n",
    "    #    char = '' # represent end of poem\n",
    "    return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[107, 107, 72]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.full(seq_length_char-1, char_to_int[''])) + [poemX[start][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'n'],\n",
       " ['an', ' '],\n",
       " ['an ', 'o'],\n",
       " ['an o', 'a'],\n",
       " ['an oa', 's'],\n",
       " ['an oas', 'i'],\n",
       " ['an oasi', 's'],\n",
       " ['an oasis', '\\n'],\n",
       " ['an oasis\\n', 'i'],\n",
       " ['an oasis\\ni', 'n'],\n",
       " ['an oasis\\nin', ' '],\n",
       " ['an oasis\\nin ', 't'],\n",
       " ['an oasis\\nin t', 'h'],\n",
       " ['an oasis\\nin th', 'e'],\n",
       " ['an oasis\\nin the', ' '],\n",
       " ['an oasis\\nin the ', 'B'],\n",
       " ['an oasis\\nin the B', 'i'],\n",
       " ['an oasis\\nin the Bi', 'b'],\n",
       " ['an oasis\\nin the Bib', 'l'],\n",
       " ['an oasis\\nin the Bibl', 'e'],\n",
       " ['an oasis\\nin the Bible', ' '],\n",
       " ['an oasis\\nin the Bible ', 'B'],\n",
       " ['an oasis\\nin the Bible B', 'e'],\n",
       " ['an oasis\\nin the Bible Be', 'l'],\n",
       " ['an oasis\\nin the Bible Bel', 't'],\n",
       " ['an oasis\\nin the Bible Belt', ' '],\n",
       " ['an oasis\\nin the Bible Belt ', '-'],\n",
       " ['an oasis\\nin the Bible Belt -', '-'],\n",
       " ['an oasis\\nin the Bible Belt --', '\\n'],\n",
       " ['an oasis\\nin the Bible Belt --\\n', 'a'],\n",
       " ['an oasis\\nin the Bible Belt --\\na', 'd'],\n",
       " ['an oasis\\nin the Bible Belt --\\nad', 'u'],\n",
       " ['an oasis\\nin the Bible Belt --\\nadu', 'l'],\n",
       " ['an oasis\\nin the Bible Belt --\\nadul', 't'],\n",
       " ['an oasis\\nin the Bible Belt --\\nadult', ' '],\n",
       " ['an oasis\\nin the Bible Belt --\\nadult ', 'b'],\n",
       " ['an oasis\\nin the Bible Belt --\\nadult b', 'o'],\n",
       " ['an oasis\\nin the Bible Belt --\\nadult bo', 'o'],\n",
       " ['an oasis\\nin the Bible Belt --\\nadult boo', 'k'],\n",
       " ['an oasis\\nin the Bible Belt --\\nadult book', ' '],\n",
       " ['n oasis\\nin the Bible Belt --\\nadult book ', 's'],\n",
       " [' oasis\\nin the Bible Belt --\\nadult book s', 't'],\n",
       " ['oasis\\nin the Bible Belt --\\nadult book st', 'o'],\n",
       " ['asis\\nin the Bible Belt --\\nadult book sto', 'r'],\n",
       " ['sis\\nin the Bible Belt --\\nadult book stor', 'e'],\n",
       " ['is\\nin the Bible Belt --\\nadult book store', '◘'],\n",
       " ['a', 'm'],\n",
       " ['am', 'o'],\n",
       " ['amo', 'r'],\n",
       " ['amor', 'e'],\n",
       " ['amore', 't'],\n",
       " ['amoret', 't'],\n",
       " ['amorett', 'i'],\n",
       " ['amoretti', ' '],\n",
       " ['amoretti ', 's'],\n",
       " ['amoretti s', 'o'],\n",
       " ['amoretti so', 'n'],\n",
       " ['amoretti son', 'n'],\n",
       " ['amoretti sonn', 'e'],\n",
       " ['amoretti sonne', 't'],\n",
       " ['amoretti sonnet', ' '],\n",
       " ['amoretti sonnet ', 'x'],\n",
       " ['amoretti sonnet x', 'x'],\n",
       " ['amoretti sonnet xx', 'v'],\n",
       " ['amoretti sonnet xxv', 'i'],\n",
       " ['amoretti sonnet xxvi', '\\n'],\n",
       " ['amoretti sonnet xxvi\\n', 'e'],\n",
       " ['amoretti sonnet xxvi\\ne', '\\n'],\n",
       " ['amoretti sonnet xxvi\\ne\\n', 's'],\n",
       " ['amoretti sonnet xxvi\\ne\\ns', 'p'],\n",
       " ['amoretti sonnet xxvi\\ne\\nsp', 'e'],\n",
       " ['amoretti sonnet xxvi\\ne\\nspe', 'n'],\n",
       " ['amoretti sonnet xxvi\\ne\\nspen', 's'],\n",
       " ['amoretti sonnet xxvi\\ne\\nspens', 'e'],\n",
       " ['amoretti sonnet xxvi\\ne\\nspense', 'r'],\n",
       " ['amoretti sonnet xxvi\\ne\\nspenser', '◘'],\n",
       " ['t', 'h'],\n",
       " ['th', 'e'],\n",
       " ['the', 'r'],\n",
       " ['ther', 'e']]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[''.join([poemchar(char) for char in pattern]), poemchar(next_char)] \\\n",
    " for _, next_char, pattern in zip(range(0,80,1), corpusY, corpusX)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights/letter/letter-weights-corrected-35-3.0577.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probs = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t   t    l  drene      e  teer   h   l     nt ee e e    as e    s  n   e    elt           o    e sa ean o  e a  alt     ae eun  e e   oe  e isao e  t    ee h  roetne     e  re eeh  o  r ae t tene s    \n",
      "Done.\n",
      "['t', ' ', ' ', ' ', 't', ' ', ' ', ' ', ' ', 'l', ' ', ' ', 'd', 'r', 'e', 'n', 'e', ' ', ' ', ' ', ' ', ' ', ' ', 'e', ' ', ' ', 't', 'e', 'e', 'r', ' ', ' ', ' ', 'h', ' ', ' ', ' ', 'l', ' ', ' ', ' ', ' ', ' ', 'n', 't', ' ', 'e', 'e', ' ', 'e', ' ', 'e', ' ', ' ', ' ', ' ', 'a', 's', ' ', 'e', ' ', ' ', ' ', ' ', 's', ' ', ' ', 'n', ' ', ' ', ' ', 'e', ' ', ' ', ' ', ' ', 'e', 'l', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'o', ' ', ' ', ' ', ' ', 'e', ' ', 's', 'a', ' ', 'e', 'a', 'n', ' ', 'o', ' ', ' ', 'e', ' ', 'a', ' ', ' ', 'a', 'l', 't', ' ', ' ', ' ', ' ', ' ', 'a', 'e', ' ', 'e', 'u', 'n', ' ', ' ', 'e', ' ', 'e', ' ', ' ', ' ', 'o', 'e', ' ', ' ', 'e', ' ', 'i', 's', 'a', 'o', ' ', 'e', ' ', ' ', 't', ' ', ' ', ' ', ' ', 'e', 'e', ' ', 'h', ' ', ' ', 'r', 'o', 'e', 't', 'n', 'e', ' ', ' ', ' ', ' ', ' ', 'e', ' ', ' ', 'r', 'e', ' ', 'e', 'e', 'h', ' ', ' ', 'o', ' ', ' ', 'r', ' ', 'a', 'e', ' ', 't', ' ', 't', 'e', 'n', 'e', ' ', 's', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "start = np.random.randint(0, len(poemX)-1)\n",
    "while start == endpoem_charindex: # don't start with end of the poem\n",
    "    start = np.random.randint(0, len(poemX)-1)\n",
    "    \n",
    "pattern = (poemX[start][0]).copy()\n",
    "gen_poem = ([poemX[start][0][-1]]).copy()\n",
    "\n",
    "[print(poemchar(char), end='') for char in pattern]\n",
    "# generate characters\n",
    "for i in range(200):\n",
    "    x = np.reshape([char / float(n_vocab) for char in pattern], (1, len(pattern), 1))\n",
    "\n",
    "    prediction = model.predict(x, verbose=0)[0] * float(n_vocab)\n",
    "    index = sample(prediction, 0.3)\n",
    "            \n",
    "    result = poemchar(index)\n",
    "    \n",
    "    if result == '◘':\n",
    "        break;\n",
    "    \n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(result, end='')\n",
    "    pattern.append(index)\n",
    "    gen_poem.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "print(\"\\nDone.\")\n",
    "print([poemchar(char) for char in gen_poem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN word testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words:  447891\n",
      "Total Vocab:  24046\n"
     ]
    }
   ],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "corpuswords_raw = flatten(list(haikus_train_df['text_withtokens_clean']))\n",
    "\n",
    "words = sorted(set(corpuswords_raw))\n",
    "word_to_int = dict((w, i) for i, w in enumerate(words))\n",
    "\n",
    "n_words = len(corpuswords_raw)\n",
    "n_vocab_words = len(words)\n",
    "print(\"Total Words: \", n_words)\n",
    "print(\"Total Vocab: \", n_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<eNd>',\n",
       " '<nEXt>',\n",
       " 'a',\n",
       " 'aaaa',\n",
       " 'aah',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abating',\n",
       " 'abattoir',\n",
       " 'abbess',\n",
       " 'abbey',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abcs',\n",
       " 'abduction',\n",
       " 'abed',\n",
       " 'abel',\n",
       " 'abelard',\n",
       " 'aberration',\n",
       " 'abhor',\n",
       " 'abhorred',\n",
       " 'abide',\n",
       " 'abilene',\n",
       " 'abjure',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ablowing',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abodes',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abord',\n",
       " 'abortion',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abraham',\n",
       " 'abramoff',\n",
       " 'abreast',\n",
       " 'abriman',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'absalom',\n",
       " 'abscond',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absently',\n",
       " 'absinthe',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolution',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'abstain',\n",
       " 'abstemious',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstractedlyone',\n",
       " 'abstraction',\n",
       " 'absurd',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abuses',\n",
       " 'abydos',\n",
       " 'abyss',\n",
       " 'abysses',\n",
       " 'acacia',\n",
       " 'academy',\n",
       " 'acadian',\n",
       " 'acadians',\n",
       " 'acc',\n",
       " 'acceleration',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'acclaim',\n",
       " 'acclaims',\n",
       " 'accolade',\n",
       " 'accommodate',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordion',\n",
       " 'accordions',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accoutrements',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulation',\n",
       " 'accursed',\n",
       " 'accurst',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accustomed',\n",
       " 'acetone',\n",
       " 'ache',\n",
       " 'ached',\n",
       " 'acheron',\n",
       " 'aches',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achiever',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'acknowledgment',\n",
       " 'acolytes',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acoustically',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisition',\n",
       " 'acquitted',\n",
       " 'acre',\n",
       " 'acreage',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acrisius',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actuarial',\n",
       " 'actuary',\n",
       " 'acuminata',\n",
       " 'acupuncture',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adah',\n",
       " 'adam',\n",
       " 'adamantine',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addenda',\n",
       " 'adder',\n",
       " 'addicted',\n",
       " 'addictions',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addison',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'adds',\n",
       " 'adepts',\n",
       " 'adequate',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adhesives',\n",
       " 'adieu',\n",
       " 'adirondack',\n",
       " 'adj',\n",
       " 'adjoining',\n",
       " 'adjudge',\n",
       " 'adjuring',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjusts',\n",
       " 'administered',\n",
       " 'admirable',\n",
       " 'admiral',\n",
       " 'admirals',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admiring',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admonish',\n",
       " 'admonitions',\n",
       " 'ado',\n",
       " 'adobe',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adonai',\n",
       " 'adonis',\n",
       " 'adopted',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adoring',\n",
       " 'adorn',\n",
       " 'adorned',\n",
       " 'adorner',\n",
       " 'adorning',\n",
       " 'adornment',\n",
       " 'adorns',\n",
       " 'adown',\n",
       " 'adrift',\n",
       " 'adroitly',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulterated',\n",
       " 'adulterous',\n",
       " 'adv',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'advents',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adverbial',\n",
       " 'adverbs',\n",
       " 'adversary',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisedly',\n",
       " 'advising',\n",
       " 'advocate',\n",
       " 'adze',\n",
       " 'aegean',\n",
       " 'aeolian',\n",
       " 'aeolus',\n",
       " 'aeons',\n",
       " 'aerated',\n",
       " 'aereal',\n",
       " 'aerial',\n",
       " 'aerie',\n",
       " 'aeronautical',\n",
       " 'aesthetic',\n",
       " 'aesthetics',\n",
       " 'aethereal',\n",
       " 'afar',\n",
       " 'aff',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affair\\x97',\n",
       " 'affectation',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affinity',\n",
       " 'affirmative',\n",
       " 'afflicted',\n",
       " 'afflicting',\n",
       " 'afford',\n",
       " 'affords',\n",
       " 'affray',\n",
       " 'affright',\n",
       " 'affrighting',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afghans',\n",
       " 'afield',\n",
       " 'aflame',\n",
       " 'aflare',\n",
       " 'afloat',\n",
       " 'aforetime',\n",
       " 'afraid',\n",
       " 'afresh',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'after',\n",
       " 'afterbirth',\n",
       " 'afterglow',\n",
       " 'afterimage',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftershave',\n",
       " 'aftershock',\n",
       " 'aftershocks',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'againstness',\n",
       " 'agate',\n",
       " 'agave',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agenda',\n",
       " 'ages',\n",
       " 'aggravate',\n",
       " 'aggravated',\n",
       " 'aggression',\n",
       " 'aggressor’s',\n",
       " 'aggrieved',\n",
       " 'aghast',\n",
       " 'agib',\n",
       " 'aging',\n",
       " 'agitate',\n",
       " 'agitated',\n",
       " 'agitates',\n",
       " 'agitation',\n",
       " 'agleam',\n",
       " 'agloom',\n",
       " 'aglow',\n",
       " 'ago',\n",
       " 'agonies',\n",
       " 'agonized',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreements',\n",
       " 'ague',\n",
       " 'ah',\n",
       " 'ahab',\n",
       " 'ahae',\n",
       " 'ahead',\n",
       " 'ahelion',\n",
       " 'ahh',\n",
       " 'ahhs',\n",
       " 'ahkond',\n",
       " 'ahkoond',\n",
       " 'aho',\n",
       " 'ahoy',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aids',\n",
       " 'aik',\n",
       " 'ail',\n",
       " 'ails',\n",
       " 'aim',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'airbus',\n",
       " 'airily',\n",
       " 'airing',\n",
       " 'airless',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airs',\n",
       " 'airy',\n",
       " 'air\\x96',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'ajar',\n",
       " 'ajdabiya',\n",
       " 'ak',\n",
       " 'akhilleus',\n",
       " 'akin',\n",
       " 'akrokeraunian',\n",
       " 'akutagawa',\n",
       " 'al',\n",
       " 'alabaster',\n",
       " 'alack',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarms',\n",
       " 'alarums',\n",
       " 'alas',\n",
       " 'alastor',\n",
       " 'alba',\n",
       " 'albans',\n",
       " 'albany',\n",
       " 'albatross',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albrecht',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcala',\n",
       " 'alchemied',\n",
       " 'alchemy',\n",
       " 'alcohol',\n",
       " 'alcoves',\n",
       " 'alden',\n",
       " 'alder',\n",
       " 'alders',\n",
       " 'aldrin',\n",
       " 'ale',\n",
       " 'alembic',\n",
       " 'aleppo',\n",
       " 'alert',\n",
       " 'alexander',\n",
       " 'alexanders',\n",
       " 'alexandrian',\n",
       " 'alfred',\n",
       " 'algebar',\n",
       " 'algebra',\n",
       " 'alhambra',\n",
       " 'ali',\n",
       " 'aliases',\n",
       " 'alibi',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alight',\n",
       " 'alighting',\n",
       " 'alights',\n",
       " 'aligned',\n",
       " 'alike',\n",
       " 'alit',\n",
       " 'alive',\n",
       " 'alka',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'allay',\n",
       " 'alleged',\n",
       " 'allegiance',\n",
       " 'allegretto',\n",
       " 'allegro',\n",
       " 'alleluias',\n",
       " 'alley',\n",
       " 'alleys',\n",
       " 'alleyway',\n",
       " 'allhallows',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'allopathic',\n",
       " 'allot',\n",
       " 'allotment',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'alloy',\n",
       " 'alls',\n",
       " 'allude',\n",
       " 'allure',\n",
       " 'allusion',\n",
       " 'allways',\n",
       " 'ally',\n",
       " 'almanac',\n",
       " 'almanack',\n",
       " 'almandine',\n",
       " 'almightie',\n",
       " 'almighty',\n",
       " 'almond',\n",
       " 'almonds',\n",
       " 'almoners',\n",
       " 'almost',\n",
       " 'alms',\n",
       " 'almshouse',\n",
       " 'aloe',\n",
       " 'aloes',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'alonest',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'aloosa',\n",
       " 'alors',\n",
       " 'alotted',\n",
       " 'aloud',\n",
       " 'alphabet',\n",
       " 'alphabets',\n",
       " 'alpine',\n",
       " 'alps',\n",
       " 'alraschid',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alsace',\n",
       " 'alsatian',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altars',\n",
       " 'alter',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'althea',\n",
       " 'altho',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'alto',\n",
       " 'altogether',\n",
       " 'alum',\n",
       " 'aluminum',\n",
       " 'alva',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'alyssum',\n",
       " 'alzheimer',\n",
       " 'alzheimers',\n",
       " 'am',\n",
       " 'amain',\n",
       " 'amaranth',\n",
       " 'amaryllis',\n",
       " 'amassing',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazonia',\n",
       " 'amazons',\n",
       " 'ambarvalia',\n",
       " 'ambassadors',\n",
       " 'amber',\n",
       " 'ambers',\n",
       " 'ambiguous',\n",
       " 'ambit',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'amble',\n",
       " 'ambling',\n",
       " 'amblongusses',\n",
       " 'ambrosial',\n",
       " 'ambulance',\n",
       " 'ambulation',\n",
       " 'ambush',\n",
       " 'amen',\n",
       " 'amended',\n",
       " 'amendment',\n",
       " 'amends',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'amerika',\n",
       " 'ametas',\n",
       " 'amethyst',\n",
       " 'amethysts',\n",
       " 'amiable',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amity',\n",
       " 'ammonia',\n",
       " 'amnesia',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amoretti',\n",
       " 'amorous',\n",
       " 'amorphas',\n",
       " 'amorphous',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'amp',\n",
       " 'ampersand',\n",
       " 'amphibian',\n",
       " 'amphibians',\n",
       " 'amphictrion',\n",
       " 'amphitheatre',\n",
       " 'ample',\n",
       " 'ampler',\n",
       " 'amplest',\n",
       " 'amptman',\n",
       " 'amsterdam',\n",
       " 'amulets',\n",
       " 'amurath',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusedly',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anah',\n",
       " 'anahit',\n",
       " 'analgesia',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'anarchs',\n",
       " 'anarchy',\n",
       " 'anas',\n",
       " 'anathema',\n",
       " 'anathematized',\n",
       " 'anatomical',\n",
       " 'anatomist',\n",
       " 'ance',\n",
       " 'ancestor',\n",
       " 'ancestors',\n",
       " 'ancestral',\n",
       " 'ancestry',\n",
       " 'anchises',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'anchovies',\n",
       " 'ancient',\n",
       " 'ancients',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andes',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'anear',\n",
       " 'anecdotes',\n",
       " 'anemone',\n",
       " 'anemones',\n",
       " 'anemonies',\n",
       " 'anew',\n",
       " 'anfractuous',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angelheaded',\n",
       " 'angelic',\n",
       " 'angelo',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angled',\n",
       " 'angler',\n",
       " 'angles',\n",
       " 'anglo',\n",
       " 'angora',\n",
       " 'angrily',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anguished',\n",
       " 'angus',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'anise',\n",
       " 'anither',\n",
       " 'anju',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'anklets',\n",
       " 'ankus',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annals',\n",
       " 'annam',\n",
       " 'anne',\n",
       " 'annemeekee',\n",
       " 'annette',\n",
       " 'annexation',\n",
       " 'annihilated',\n",
       " 'annihilating',\n",
       " 'annihilation',\n",
       " 'anniversary',\n",
       " 'anniversary\\x97',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcements',\n",
       " 'announcer',\n",
       " 'announces',\n",
       " 'announcing',\n",
       " 'annulled',\n",
       " 'annulling',\n",
       " 'anoint',\n",
       " 'anoints',\n",
       " 'anon',\n",
       " 'anonymity',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'another\\x92s',\n",
       " 'ansel',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answerer',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'antarctica',\n",
       " 'antechamber',\n",
       " 'antedated',\n",
       " 'antenna',\n",
       " 'antennae',\n",
       " 'antennas',\n",
       " 'anthill',\n",
       " 'anthology',\n",
       " 'anthropology',\n",
       " 'anti',\n",
       " 'antibody',\n",
       " 'anticipate',\n",
       " 'anticipates',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antics',\n",
       " 'antidotes',\n",
       " 'antient',\n",
       " 'antioch',\n",
       " 'antique',\n",
       " 'antiquity',\n",
       " 'antler',\n",
       " 'antlers',\n",
       " 'antofagastas',\n",
       " 'antoine',\n",
       " 'antonius',\n",
       " 'antony',\n",
       " 'antonys',\n",
       " 'ants',\n",
       " 'ants’',\n",
       " 'antwerp',\n",
       " 'anvil',\n",
       " 'anxieties',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyoldhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apace',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'ape',\n",
       " 'apennines',\n",
       " 'aperture',\n",
       " 'apes',\n",
       " 'aphids',\n",
       " 'apocalypse',\n",
       " 'apogee',\n",
       " 'apollinax',\n",
       " 'apollos',\n",
       " 'apologetically',\n",
       " 'apologies',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apology\\x97',\n",
       " 'apostate',\n",
       " 'apostle',\n",
       " 'apostles',\n",
       " 'app',\n",
       " 'appalachian',\n",
       " 'appalled',\n",
       " 'appalls',\n",
       " 'appanage',\n",
       " 'apparel',\n",
       " 'apparelled',\n",
       " 'apparently',\n",
       " 'apparition',\n",
       " 'apparitions',\n",
       " 'appartment',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'appeased',\n",
       " 'appendix',\n",
       " 'appetite',\n",
       " 'appetites',\n",
       " 'applauding',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'appleblooms',\n",
       " 'applemint',\n",
       " 'apples',\n",
       " 'applesauce',\n",
       " 'apples\\x97',\n",
       " 'applewood',\n",
       " 'apple\\x97',\n",
       " 'appliance',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'apportioned',\n",
       " 'appreciate',\n",
       " 'appreciations',\n",
       " 'appreciative',\n",
       " 'apprehended',\n",
       " 'apprehends',\n",
       " 'apprehension',\n",
       " 'apprentice',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'approbation',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'apricot',\n",
       " 'apricots',\n",
       " 'april',\n",
       " 'aproned',\n",
       " 'apt',\n",
       " 'aptly',\n",
       " 'aqua',\n",
       " 'aquajogging',\n",
       " 'aquarium',\n",
       " 'aqueduct',\n",
       " 'aquinas',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabesqued',\n",
       " 'arabesques',\n",
       " 'arabia',\n",
       " 'arabic',\n",
       " 'araby',\n",
       " 'arak',\n",
       " 'ararat',\n",
       " 'arb',\n",
       " 'arbiter',\n",
       " 'arbitrement',\n",
       " 'arbor',\n",
       " 'arbors',\n",
       " 'arbour',\n",
       " 'arc',\n",
       " 'arcadia',\n",
       " 'arcadian',\n",
       " 'arcady',\n",
       " 'arcane',\n",
       " 'arch',\n",
       " 'archaic',\n",
       " 'archbishop',\n",
       " 'arched',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'archery',\n",
       " 'arches',\n",
       " 'arching',\n",
       " 'archipelago',\n",
       " 'architectures',\n",
       " 'archive',\n",
       " 'archly',\n",
       " 'archy',\n",
       " 'arctic',\n",
       " 'ardennes',\n",
       " 'ardent',\n",
       " 'ardently',\n",
       " 'ardor',\n",
       " 'ardour',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'argent',\n",
       " 'argot',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'argus',\n",
       " 'ari',\n",
       " 'aria',\n",
       " 'ariadne',\n",
       " 'arid',\n",
       " 'aright',\n",
       " 'ariosto',\n",
       " 'arise',\n",
       " 'arisen',\n",
       " 'arises',\n",
       " 'aristocrats',\n",
       " 'arizona',\n",
       " 'ark',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armada',\n",
       " 'armadillo',\n",
       " 'armchair',\n",
       " 'armchairs',\n",
       " 'armed',\n",
       " 'armenian',\n",
       " 'armful',\n",
       " 'armies',\n",
       " 'arming',\n",
       " 'armistice',\n",
       " 'armless',\n",
       " 'armload',\n",
       " 'armor',\n",
       " 'armored',\n",
       " 'armour',\n",
       " 'armoured',\n",
       " 'armoury',\n",
       " 'arms',\n",
       " 'armsful',\n",
       " 'army',\n",
       " 'arn',\n",
       " 'arno',\n",
       " 'arnold',\n",
       " 'arnolds',\n",
       " 'aroma',\n",
       " 'aroon',\n",
       " 'arose',\n",
       " 'around',\n",
       " 'aroused',\n",
       " 'arousing',\n",
       " 'arpeggios',\n",
       " 'arprobus',\n",
       " 'arrang',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranges',\n",
       " 'arras',\n",
       " 'array',\n",
       " 'arrayed',\n",
       " 'arrest',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'arrows',\n",
       " 'arroyo',\n",
       " 'arsenal',\n",
       " 'arsonist',\n",
       " 'art',\n",
       " 'arteries',\n",
       " 'arthritis',\n",
       " 'arthur',\n",
       " 'artic',\n",
       " 'artichoke',\n",
       " 'artichokes',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'artifice',\n",
       " 'artificer',\n",
       " 'artificial',\n",
       " 'artillery',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  422763\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length_word = 15\n",
    "\n",
    "word_poemX = []\n",
    "word_poemY = []\n",
    "n_wordpatterns = 0\n",
    "\n",
    "word_corpusX = []\n",
    "word_corpusY = []\n",
    "for poem_index in range(0, n_poems):\n",
    "\n",
    "    wordX = []\n",
    "    wordY = []\n",
    "    poem = haikus_train_df['text_withtokens_clean'].iloc[poem_index]\n",
    "    # add padding to poem\n",
    "    poem = list(np.full(seq_length_word - 1, '')) + list(poem)\n",
    "    for i in range(0,  len(poem) - seq_length_word, 1):\n",
    "        seq_in = poem[i:i + seq_length_word]\n",
    "        seq_out = poem[i + seq_length_word]\n",
    "        wordX.append([word_to_int[word] for word in seq_in])\n",
    "        wordY.append(word_to_int[seq_out])\n",
    "    n_wordpatterns = max(n_wordpatterns, len(wordX))\n",
    "    \n",
    "    word_poemX.append(wordX)\n",
    "    word_poemY.append(wordY)\n",
    "    \n",
    "    word_corpusX += wordX\n",
    "    word_corpusY += wordY\n",
    "\n",
    "n_wordpatterns = len(word_corpusX)\n",
    "print(\"Total Patterns: \", n_wordpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16213],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16213, 12752],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16213, 12752, 2],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16213, 12752, 2, 21167],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16213, 12752, 2, 21167, 19984],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 16213, 12752, 2, 21167, 19984, 9626],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 16213, 12752, 2, 21167, 19984, 9626, 394],\n",
       " [0, 0, 0, 0, 0, 0, 0, 16213, 12752, 2, 21167, 19984, 9626, 394, 2],\n",
       " [0, 0, 0, 0, 0, 0, 16213, 12752, 2, 21167, 19984, 9626, 394, 2, 20998],\n",
       " [0, 0, 0, 0, 0, 16213, 12752, 2, 21167, 19984, 9626, 394, 2, 20998, 23670],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  16213,\n",
       "  12752,\n",
       "  2,\n",
       "  21167,\n",
       "  19984,\n",
       "  9626,\n",
       "  394,\n",
       "  2,\n",
       "  20998,\n",
       "  23670,\n",
       "  18438]]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights/word/word-weights-new-200-3.7964.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token(token):\n",
    "    \n",
    "    if token == '<nEXt>':\n",
    "        print()\n",
    "    elif token == '<eNd>':\n",
    "        print()\n",
    "    elif token != '':\n",
    "        print(token, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 609]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_poemX[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn your all \n",
      "i bowed she \n",
      "full on both within of plans day \n",
      "\n",
      "['arn', 'your', 'all', '<nEXt>', 'i', 'bowed', 'she', '<nEXt>', 'full', 'on', 'both', 'within', 'of', 'plans', 'day', '<nEXt>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "int_to_word = dict((i, w) for i, w in enumerate(words))\n",
    "\n",
    "start = np.random.randint(0, n_poems)\n",
    "pattern = word_poemX[start][0]\n",
    "gen_poem = [pattern[-1]]\n",
    "# generate words\n",
    "for i in range(200):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab_words)\n",
    "    prediction = model.predict(x, verbose=0)[0]\n",
    "    index = sample(prediction, 0.99)\n",
    "    #index = np.argmax(prediction)\n",
    "    \n",
    "    # avoid repeating\n",
    "    #if index == pattern[-1]:\n",
    "    #    prediction[index] = 0\n",
    "    #    index = np.argmax(prediction)\n",
    "    \n",
    "    result = int_to_word[index]\n",
    "    if result == '':\n",
    "        prediction[index] = 0\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_word[index]\n",
    "    \n",
    "    if result == '<eNd>':\n",
    "        break;\n",
    "    \n",
    "    seq_in = [int_to_word[value] for value in pattern]\n",
    "    \n",
    "    pattern.append(index)\n",
    "    if result != '' and not (gen_poem[-1] == '<nEXt>' and result == '<nEXt>'):\n",
    "        gen_poem.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "[print_token(int_to_word[value]) for value in gen_poem]\n",
    "print()\n",
    "\n",
    "print([int_to_word[value] for value in gen_poem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.45 GiB for an array with shape (2196018, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-190783c739bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglove2word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mglove_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0madd_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.45 GiB for an array with shape (2196018, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts import glove2word2vec\n",
    "import os\n",
    "\n",
    "glove_file = './data/image_to_tect/glove.840B.300d.txt'\n",
    "tmp_file = './data/image_to_text/glovetmp.txt'\n",
    "\n",
    "if not os.path.isfile(tmp_file):\n",
    "    _ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "corpuswords_raw = flatten(list(haikus_train_df['text_withtokens']))\n",
    "\n",
    "words = sorted(set(corpuswords_raw))\n",
    "word_to_int = dict((w, i) for i, w in enumerate(words))\n",
    "int_to_word = dict((i, w) for i, w in enumerate(words))\n",
    "\n",
    "n_words = len(corpuswords_raw)\n",
    "n_vocab_words = len(words)\n",
    "print(\"Total Words: \", n_words)\n",
    "print(\"Total Vocab: \", n_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "\n",
    "if os.path.isfile('./data/haiku_train_wordembed.npz'):\n",
    "    loaded = np.load('./data/haiku_train_wordembed.npz', allow_pickle=True)\n",
    "    \n",
    "    word_poemX = loaded['X']\n",
    "    word_poemY = loaded['Y']\n",
    "    \n",
    "    seq_length_word = len(word_poemX[0])\n",
    "else:\n",
    "    seq_length_word = 15\n",
    "\n",
    "    word_poemX = []\n",
    "    word_poemY = []\n",
    "    n_wordpatterns = 0\n",
    "\n",
    "    word_corpusX = []\n",
    "    word_corpusY = []\n",
    "    for poem_index in range(0, n_poems):\n",
    "\n",
    "        wordX = []\n",
    "        wordY = []\n",
    "        poem = haikus_train_df['text_withtokens'].iloc[poem_index]\n",
    "        # add padding to poem\n",
    "        poem = list(np.full(seq_length_word - 1, '')) + list(poem)\n",
    "        for i in range(0,  len(poem) - seq_length_word, 1):\n",
    "            seq_in = poem[i:i + seq_length_word]\n",
    "            seq_out = poem[i + seq_length_word]\n",
    "            wordX.append([word_to_int[word] for word in seq_in])\n",
    "            wordY.append(word_to_int[seq_out])\n",
    "        n_wordpatterns = max(n_wordpatterns, len(wordX))\n",
    "\n",
    "        word_poemX.append(wordX)\n",
    "        word_poemY.append(wordY)\n",
    "\n",
    "        word_corpusX += wordX\n",
    "        word_corpusY += wordY\n",
    "\n",
    "    np.savez_compressed('./data/haiku_train_wordembed.npz', X=np.array(word_poemX), Y=np.array(word_poemY))\n",
    "\n",
    "    n_wordpatterns = len(word_corpusX)\n",
    "    print(\"Total Patterns: \", n_wordpatterns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(text, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += glove_model[word].reshape((1, size))\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('weights/word_embedding/wordembed-weights-70-2.5563.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "getsizeof(model) / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6996]"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15, 300)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[buildWordVector([int_to_word[word]], 300)[0] for word in pattern]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satins \n",
      "the pages of the sand \n",
      "fills the air \n",
      "['satins', '<nEXt>', 'the', 'pages', 'of', 'the', 'sand', '<nEXt>', 'fills', 'the', 'air']\n"
     ]
    }
   ],
   "source": [
    "temperature = .5\n",
    "\n",
    "start = np.random.randint(0, n_vocab_words)\n",
    "pattern = list(np.zeros(14)) + [start]\n",
    "gen_poem = [pattern[-1]]\n",
    "\n",
    "# generate words\n",
    "for i in range(200):\n",
    "    x = np.array([[buildWordVector([int_to_word[word]], 300)[0] for word in pattern]])\n",
    "    prediction = model.predict(x, verbose=0)[0]\n",
    "    index = sample(prediction, temperature)\n",
    "    #index = np.argmax(prediction)\n",
    "    \n",
    "    # avoid repeating\n",
    "    #if index == pattern[-1]:\n",
    "    #    prediction[index] = 0\n",
    "    #    index = np.argmax(prediction)\n",
    "    \n",
    "    while index >= len(int_to_word):\n",
    "        index = sample(prediction, temperature)\n",
    "        \n",
    "    result = int_to_word[index]\n",
    "    \n",
    "    if result == '':\n",
    "        prediction[index] = 0\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_word[index]\n",
    "    \n",
    "    if result == '<eNd>':\n",
    "        break;\n",
    "    \n",
    "    pattern.append(index)\n",
    "    if result != '':\n",
    "        gen_poem.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "[print_token(int_to_word[value]) for value in gen_poem]\n",
    "print()\n",
    "\n",
    "print([int_to_word[value] for value in gen_poem])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

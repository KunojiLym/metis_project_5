{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "RANDOM = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The haiku dataset: loading and initial cleaning\n",
    "\n",
    "This was obtained from the dataset created by Jeremy Neiman for use in his own haiku generation model, published in the last few days of 2018; Medium post <a href=\"https://towardsdatascience.com/generating-haiku-with-deep-learning-dbf5d18b4246\">here</a> and Github for the dataset <a href=\"https://github.com/docmarionum1/haikurnn/tree/master/input/poems\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikus_df = pd.read_csv('./data/image_to_text/haikus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143137 entries, 0 to 143136\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   0            143120 non-null  object\n",
      " 1   1            143123 non-null  object\n",
      " 2   2            142954 non-null  object\n",
      " 3   source       143137 non-null  object\n",
      " 4   0_syllables  143137 non-null  object\n",
      " 5   1_syllables  143137 non-null  object\n",
      " 6   2_syllables  143137 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "haikus_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twaiku         111727\n",
       "img2poems       11808\n",
       "sballas          8142\n",
       "gutenberg        5524\n",
       "tempslibres      4800\n",
       "haikuzao         1136\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haikus_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neiman discardes the twaiku source from his final model because the poetry there appears to be low quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "img2poems      11808\n",
       "sballas         8142\n",
       "gutenberg       5524\n",
       "tempslibres     4800\n",
       "haikuzao        1136\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haikus_notwitter_df = haikus_df[haikus_df.source != 'twaiku']\n",
    "\n",
    "haikus_notwitter_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>source</th>\n",
       "      <th>0_syllables</th>\n",
       "      <th>1_syllables</th>\n",
       "      <th>2_syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memorial Day --</td>\n",
       "      <td>a shadow for each</td>\n",
       "      <td>white cross</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring rain -</td>\n",
       "      <td>as the doctor speaks</td>\n",
       "      <td>i think of lilacs</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>2,3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spring moonset --</td>\n",
       "      <td>a rice ball for</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>3,4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunny afternoon</td>\n",
       "      <td>an old man lingers</td>\n",
       "      <td>near the mailbox</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cinco de mayo</td>\n",
       "      <td>horses roll</td>\n",
       "      <td>in the shallows</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31405</th>\n",
       "      <td>Jupiter's throne, so dishonestly</td>\n",
       "      <td>won, it was I who secured it: Color and ivory,</td>\n",
       "      <td>marble and bronze, not to mention the poems.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>9</td>\n",
       "      <td>13,14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31406</th>\n",
       "      <td>Now, all intelligent</td>\n",
       "      <td>men look upon me</td>\n",
       "      <td>in kindness.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31407</th>\n",
       "      <td>They like to Form their</td>\n",
       "      <td>own image of me, just as</td>\n",
       "      <td>the poet has done.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31408</th>\n",
       "      <td>Nor do the girls take</td>\n",
       "      <td>offense when they see me--by no</td>\n",
       "      <td>means the matrons.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31409</th>\n",
       "      <td>None finds me ugly</td>\n",
       "      <td>today, though I am</td>\n",
       "      <td>monstrously strong.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>5</td>\n",
       "      <td>5,6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31410 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0  \\\n",
       "0                       Memorial Day --   \n",
       "1                         spring rain -   \n",
       "2                     spring moonset --   \n",
       "3                       sunny afternoon   \n",
       "4                         cinco de mayo   \n",
       "...                                 ...   \n",
       "31405  Jupiter's throne, so dishonestly   \n",
       "31406              Now, all intelligent   \n",
       "31407           They like to Form their   \n",
       "31408             Nor do the girls take   \n",
       "31409                None finds me ugly   \n",
       "\n",
       "                                                    1  \\\n",
       "0                                   a shadow for each   \n",
       "1                                as the doctor speaks   \n",
       "2                                     a rice ball for   \n",
       "3                                  an old man lingers   \n",
       "4                                         horses roll   \n",
       "...                                               ...   \n",
       "31405  won, it was I who secured it: Color and ivory,   \n",
       "31406                                men look upon me   \n",
       "31407                        own image of me, just as   \n",
       "31408                 offense when they see me--by no   \n",
       "31409                              today, though I am   \n",
       "\n",
       "                                                  2       source 0_syllables  \\\n",
       "0                                       white cross  tempslibres           5   \n",
       "1                                 i think of lilacs  tempslibres         2,3   \n",
       "2                                         breakfast  tempslibres         3,4   \n",
       "3                                  near the mailbox  tempslibres           5   \n",
       "4                                   in the shallows  tempslibres           5   \n",
       "...                                             ...          ...         ...   \n",
       "31405  marble and bronze, not to mention the poems.    gutenberg           9   \n",
       "31406                                  in kindness.    gutenberg           6   \n",
       "31407                            the poet has done.    gutenberg           5   \n",
       "31408                            means the matrons.    gutenberg           5   \n",
       "31409                           monstrously strong.    gutenberg           5   \n",
       "\n",
       "      1_syllables 2_syllables  \n",
       "0               5           2  \n",
       "1               5           5  \n",
       "2               4           2  \n",
       "3               5           4  \n",
       "4               3           4  \n",
       "...           ...         ...  \n",
       "31405       13,14          11  \n",
       "31406           5           3  \n",
       "31407           7           5  \n",
       "31408           7           4  \n",
       "31409         5,6           4  \n",
       "\n",
       "[31410 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haikus_notwitter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, will only look at the lower syllable count where there are two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "syllable_cols = ['0_syllables', '1_syllables', '2_syllables']\n",
    "\n",
    "for col in syllable_cols:\n",
    "    haikus_notwitter_df[col] = haikus_notwitter_df[col].apply(lambda x: int(x.split(',')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>source</th>\n",
       "      <th>0_syllables</th>\n",
       "      <th>1_syllables</th>\n",
       "      <th>2_syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memorial Day --</td>\n",
       "      <td>a shadow for each</td>\n",
       "      <td>white cross</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring rain -</td>\n",
       "      <td>as the doctor speaks</td>\n",
       "      <td>i think of lilacs</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spring moonset --</td>\n",
       "      <td>a rice ball for</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunny afternoon</td>\n",
       "      <td>an old man lingers</td>\n",
       "      <td>near the mailbox</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cinco de mayo</td>\n",
       "      <td>horses roll</td>\n",
       "      <td>in the shallows</td>\n",
       "      <td>tempslibres</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31405</th>\n",
       "      <td>Jupiter's throne, so dishonestly</td>\n",
       "      <td>won, it was I who secured it: Color and ivory,</td>\n",
       "      <td>marble and bronze, not to mention the poems.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31406</th>\n",
       "      <td>Now, all intelligent</td>\n",
       "      <td>men look upon me</td>\n",
       "      <td>in kindness.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31407</th>\n",
       "      <td>They like to Form their</td>\n",
       "      <td>own image of me, just as</td>\n",
       "      <td>the poet has done.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31408</th>\n",
       "      <td>Nor do the girls take</td>\n",
       "      <td>offense when they see me--by no</td>\n",
       "      <td>means the matrons.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31409</th>\n",
       "      <td>None finds me ugly</td>\n",
       "      <td>today, though I am</td>\n",
       "      <td>monstrously strong.</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31410 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0  \\\n",
       "0                       Memorial Day --   \n",
       "1                         spring rain -   \n",
       "2                     spring moonset --   \n",
       "3                       sunny afternoon   \n",
       "4                         cinco de mayo   \n",
       "...                                 ...   \n",
       "31405  Jupiter's throne, so dishonestly   \n",
       "31406              Now, all intelligent   \n",
       "31407           They like to Form their   \n",
       "31408             Nor do the girls take   \n",
       "31409                None finds me ugly   \n",
       "\n",
       "                                                    1  \\\n",
       "0                                   a shadow for each   \n",
       "1                                as the doctor speaks   \n",
       "2                                     a rice ball for   \n",
       "3                                  an old man lingers   \n",
       "4                                         horses roll   \n",
       "...                                               ...   \n",
       "31405  won, it was I who secured it: Color and ivory,   \n",
       "31406                                men look upon me   \n",
       "31407                        own image of me, just as   \n",
       "31408                 offense when they see me--by no   \n",
       "31409                              today, though I am   \n",
       "\n",
       "                                                  2       source  0_syllables  \\\n",
       "0                                       white cross  tempslibres            5   \n",
       "1                                 i think of lilacs  tempslibres            2   \n",
       "2                                         breakfast  tempslibres            3   \n",
       "3                                  near the mailbox  tempslibres            5   \n",
       "4                                   in the shallows  tempslibres            5   \n",
       "...                                             ...          ...          ...   \n",
       "31405  marble and bronze, not to mention the poems.    gutenberg            9   \n",
       "31406                                  in kindness.    gutenberg            6   \n",
       "31407                            the poet has done.    gutenberg            5   \n",
       "31408                            means the matrons.    gutenberg            5   \n",
       "31409                           monstrously strong.    gutenberg            5   \n",
       "\n",
       "       1_syllables  2_syllables  \n",
       "0                5            2  \n",
       "1                5            5  \n",
       "2                4            2  \n",
       "3                5            4  \n",
       "4                3            4  \n",
       "...            ...          ...  \n",
       "31405           13           11  \n",
       "31406            5            3  \n",
       "31407            7            5  \n",
       "31408            7            4  \n",
       "31409            5            4  \n",
       "\n",
       "[31410 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haikus_notwitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>source</th>\n",
       "      <th>0_syllables</th>\n",
       "      <th>1_syllables</th>\n",
       "      <th>2_syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, source, 0_syllables, 1_syllables, 2_syllables]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haikus_notwitter_df[haikus_notwitter_df['source'].isna()].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaN in '0' - '2' with '', drop the remaining null entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "line_cols = ['0', '1', '2']\n",
    "\n",
    "for col in line_cols:\n",
    "    haikus_notwitter_df[col].fillna('', inplace=True)\n",
    "    \n",
    "haikus_notwitter_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column that has the whole text of the 3-line poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "haikus_notwitter_df['text'] = haikus_notwitter_df['0'] + ' ' + haikus_notwitter_df['1'] + ' ' + haikus_notwitter_df['2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...a column with all lower case and without punctuation.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "haikus_notwitter_df['text_clean'] = haikus_notwitter_df.text.map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and one that has tokens for line breaks and end of poem <strike>and is a list of words/tokens</strike>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "haikus_notwitter_df['text_withtokens'] = haikus_notwitter_df['0'].apply(lambda x: x.split(' ') + ['<nEXt>']) \\\n",
    "                                        + haikus_notwitter_df['1'].apply(lambda x: x.split(' ') + ['<nEXt>']) \\\n",
    "                                        + haikus_notwitter_df['2'].apply(lambda x: x.split(' ') + ['<eNd>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# haikus_notwitter_df['text_withtokens'] = haikus_notwitter_df['0'] + ' <nEXt> ' \\\n",
    "#                                          + haikus_notwitter_df['1'] + ' <nEXt> ' \\\n",
    "#                                          + haikus_notwitter_df['2'] + ' <eNd>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Using ↕ to represent a new line and ◘ to represent end of poe\n",
    "\n",
    "haikus_notwitter_df['textchar_withtokens'] = haikus_notwitter_df['0'] + '↕' \\\n",
    "                                         + haikus_notwitter_df['1'] + '↕' \\\n",
    "                                         + haikus_notwitter_df['2'] + '◘'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "haikus_train_df, haikus_test_df = train_test_split(haikus_notwitter_df, test_size=0.2, random_state=RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3609</th>\n",
       "      <th>12344</th>\n",
       "      <th>12027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an oasis</td>\n",
       "      <td>amoretti sonnet xxvi</td>\n",
       "      <td>there when they came mind suffered shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the Bible Belt --</td>\n",
       "      <td>e</td>\n",
       "      <td>`these be the same and not the same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult book store</td>\n",
       "      <td>spenser</td>\n",
       "      <td>a-wondering whispered mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>tempslibres</td>\n",
       "      <td>img2poems</td>\n",
       "      <td>img2poems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_syllables</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_syllables</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_syllables</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>an oasis in the Bible Belt -- adult book store</td>\n",
       "      <td>amoretti sonnet xxvi e spenser</td>\n",
       "      <td>there when they came mind suffered shame `thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_clean</th>\n",
       "      <td>an oasis in the bible belt    adult book store</td>\n",
       "      <td>amoretti sonnet xxvi e spenser</td>\n",
       "      <td>there when they came mind suffered shame  thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_withtokens</th>\n",
       "      <td>[an, oasis, &lt;nEXt&gt;, in, the, Bible, Belt, --, ...</td>\n",
       "      <td>[amoretti, sonnet, xxvi, &lt;nEXt&gt;, e, &lt;nEXt&gt;, sp...</td>\n",
       "      <td>[there, when, they, came, mind, suffered, sham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textchar_withtokens</th>\n",
       "      <td>an oasis↕in the Bible Belt --↕adult book store◘</td>\n",
       "      <td>amoretti sonnet xxvi↕e↕spenser◘</td>\n",
       "      <td>there when they came mind suffered shame↕`thes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 3609   \\\n",
       "0                                                             an oasis   \n",
       "1                                                 in the Bible Belt --   \n",
       "2                                                     adult book store   \n",
       "source                                                     tempslibres   \n",
       "0_syllables                                                          4   \n",
       "1_syllables                                                          5   \n",
       "2_syllables                                                          4   \n",
       "text                    an oasis in the Bible Belt -- adult book store   \n",
       "text_clean              an oasis in the bible belt    adult book store   \n",
       "text_withtokens      [an, oasis, <nEXt>, in, the, Bible, Belt, --, ...   \n",
       "textchar_withtokens    an oasis↕in the Bible Belt --↕adult book store◘   \n",
       "\n",
       "                                                                 12344  \\\n",
       "0                                                 amoretti sonnet xxvi   \n",
       "1                                                                    e   \n",
       "2                                                              spenser   \n",
       "source                                                       img2poems   \n",
       "0_syllables                                                          7   \n",
       "1_syllables                                                          1   \n",
       "2_syllables                                                          2   \n",
       "text                                    amoretti sonnet xxvi e spenser   \n",
       "text_clean                              amoretti sonnet xxvi e spenser   \n",
       "text_withtokens      [amoretti, sonnet, xxvi, <nEXt>, e, <nEXt>, sp...   \n",
       "textchar_withtokens                    amoretti sonnet xxvi↕e↕spenser◘   \n",
       "\n",
       "                                                                 12027  \n",
       "0                             there when they came mind suffered shame  \n",
       "1                                  `these be the same and not the same  \n",
       "2                                           a-wondering whispered mind  \n",
       "source                                                       img2poems  \n",
       "0_syllables                                                          8  \n",
       "1_syllables                                                          7  \n",
       "2_syllables                                                          4  \n",
       "text                 there when they came mind suffered shame `thes...  \n",
       "text_clean           there when they came mind suffered shame  thes...  \n",
       "text_withtokens      [there, when, they, came, mind, suffered, sham...  \n",
       "textchar_withtokens  there when they came mind suffered shame↕`thes...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haikus_train_df.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP: Throw everything into an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1849446\n",
      "Total Vocab:  107\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = ''.join(haikus_train_df['textchar_withtokens'])\n",
    "\n",
    "chars = sorted(set(list(corpus_raw)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(corpus_raw)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '\"',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '~',\n",
       " '\\x85',\n",
       " '\\x92',\n",
       " '\\x96',\n",
       " '\\x97',\n",
       " '\\xa0',\n",
       " 'à',\n",
       " 'ä',\n",
       " 'é',\n",
       " 'ü',\n",
       " 'ē',\n",
       " 'ū',\n",
       " 'ŭ',\n",
       " '\\u200b',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '…',\n",
       " '↕',\n",
       " '◘']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_poems = len(haikus_train_df)\n",
    "\n",
    "n_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max patterns per poem:  792\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 10\n",
    "\n",
    "poemX = []\n",
    "poemY = []\n",
    "n_patterns = 0\n",
    "\n",
    "corpusX = []\n",
    "corpusY = []\n",
    "for poem_index in range(0, n_poems):\n",
    "\n",
    "    textX = []\n",
    "    textY = []\n",
    "    poem = haikus_train_df['textchar_withtokens'].iloc[poem_index]\n",
    "    for i in range(0,  len(poem) - seq_length, 1):\n",
    "        seq_in = poem[i:i + seq_length]\n",
    "        seq_out = poem[i + seq_length]\n",
    "        textX.append([char_to_int[char] for char in seq_in])\n",
    "        textY.append(char_to_int[seq_out])\n",
    "    n_patterns = max(n_patterns, len(textX))\n",
    "    \n",
    "    poemX.append(textX)\n",
    "    poemY.append(textY)\n",
    "    \n",
    "    corpusX += textX\n",
    "    corpusY += textY\n",
    "\n",
    "print(\"Max patterns per poem: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoem_charindex = char_to_int['◘']\n",
    "newline_charindex = char_to_int['↕']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>105</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>105</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>105</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>105</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>105</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598173</th>\n",
       "      <td>81</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598174</th>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598175</th>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598176</th>\n",
       "      <td>70</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598177</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598178 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   1   2   3    4    5    6    7    8   9\n",
       "0        59  72   0  73   59   77   67   77  105  67\n",
       "1        72   0  73  59   77   67   77  105   67  72\n",
       "2         0  73  59  77   67   77  105   67   72   0\n",
       "3        73  59  77  67   77  105   67   72    0  78\n",
       "4        59  77  67  77  105   67   72    0   78  66\n",
       "...      ..  ..  ..  ..  ...  ...  ...  ...  ...  ..\n",
       "1598173  81  73  76  70   62    0   77   66   67  71\n",
       "1598174  73  76  70  62    0   77   66   67   71  71\n",
       "1598175  76  70  62   0   77   66   67   71   71  63\n",
       "1598176  70  62   0  77   66   67   71   71   63  76\n",
       "1598177  62   0  77  66   67   71   71   63   76  77\n",
       "\n",
       "[1598178 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(corpusX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 30,\n",
       " 67,\n",
       " 60,\n",
       " 70,\n",
       " 63,\n",
       " 0,\n",
       " 30,\n",
       " 63,\n",
       " 70,\n",
       " 78,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 105,\n",
       " 59,\n",
       " 62,\n",
       " 79,\n",
       " 70,\n",
       " 78,\n",
       " 0,\n",
       " 60,\n",
       " 73,\n",
       " 73,\n",
       " 69,\n",
       " 0,\n",
       " 77,\n",
       " 78,\n",
       " 73,\n",
       " 76,\n",
       " 63,\n",
       " 106,\n",
       " 73,\n",
       " 72,\n",
       " 72,\n",
       " 63,\n",
       " 78,\n",
       " 0,\n",
       " 82,\n",
       " 82,\n",
       " 80,\n",
       " 67,\n",
       " 105,\n",
       " 63,\n",
       " 105,\n",
       " 77,\n",
       " 74,\n",
       " 63,\n",
       " 72,\n",
       " 77,\n",
       " 63,\n",
       " 76,\n",
       " 106,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 83,\n",
       " 0,\n",
       " 61,\n",
       " 59,\n",
       " 71,\n",
       " 63,\n",
       " 0,\n",
       " 71,\n",
       " 67,\n",
       " 72,\n",
       " 62,\n",
       " 0,\n",
       " 77,\n",
       " 79,\n",
       " 64,\n",
       " 64,\n",
       " 63,\n",
       " 76,\n",
       " 63,\n",
       " 62,\n",
       " 0,\n",
       " 77,\n",
       " 66,\n",
       " 59,\n",
       " 71,\n",
       " 63,\n",
       " 105,\n",
       " 58,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 77,\n",
       " 63,\n",
       " 0,\n",
       " 60,\n",
       " 63,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 77,\n",
       " 59,\n",
       " 71,\n",
       " 63,\n",
       " 0,\n",
       " 59,\n",
       " 72,\n",
       " 62,\n",
       " 0,\n",
       " 72,\n",
       " 73,\n",
       " 78,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 77,\n",
       " 59,\n",
       " 71,\n",
       " 63,\n",
       " 105,\n",
       " 59,\n",
       " 10,\n",
       " 81,\n",
       " 73,\n",
       " 72,\n",
       " 62,\n",
       " 63,\n",
       " 76,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 0,\n",
       " 81,\n",
       " 66,\n",
       " 67,\n",
       " 77,\n",
       " 74,\n",
       " 63,\n",
       " 76,\n",
       " 63,\n",
       " 62,\n",
       " 0,\n",
       " 71,\n",
       " 67,\n",
       " 72,\n",
       " 62,\n",
       " 106,\n",
       " 76,\n",
       " 77,\n",
       " 59,\n",
       " 78,\n",
       " 67,\n",
       " 73,\n",
       " 72,\n",
       " 105,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 62,\n",
       " 59,\n",
       " 64,\n",
       " 64,\n",
       " 73,\n",
       " 62,\n",
       " 67,\n",
       " 70,\n",
       " 77,\n",
       " 0,\n",
       " 72,\n",
       " 73,\n",
       " 62,\n",
       " 62,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 105,\n",
       " 37,\n",
       " 72,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 60,\n",
       " 76,\n",
       " 63,\n",
       " 63,\n",
       " 84,\n",
       " 63,\n",
       " 106,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 77,\n",
       " 70,\n",
       " 73,\n",
       " 81,\n",
       " 0,\n",
       " 61,\n",
       " 76,\n",
       " 63,\n",
       " 59,\n",
       " 69,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 105,\n",
       " 73,\n",
       " 64,\n",
       " 0,\n",
       " 59,\n",
       " 72,\n",
       " 0,\n",
       " 59,\n",
       " 72,\n",
       " 61,\n",
       " 66,\n",
       " 73,\n",
       " 76,\n",
       " 0,\n",
       " 70,\n",
       " 67,\n",
       " 72,\n",
       " 63,\n",
       " 106,\n",
       " 66,\n",
       " 63,\n",
       " 76,\n",
       " 63,\n",
       " 0,\n",
       " 81,\n",
       " 59,\n",
       " 77,\n",
       " 0,\n",
       " 72,\n",
       " 73,\n",
       " 0,\n",
       " 77,\n",
       " 73,\n",
       " 79,\n",
       " 72,\n",
       " 62,\n",
       " 0,\n",
       " 67,\n",
       " 72,\n",
       " 0,\n",
       " 59,\n",
       " 70,\n",
       " 70,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 66,\n",
       " 73,\n",
       " 79,\n",
       " 77,\n",
       " 63,\n",
       " 105,\n",
       " 67,\n",
       " 0,\n",
       " 61,\n",
       " 73,\n",
       " 79,\n",
       " 70,\n",
       " 62,\n",
       " 0,\n",
       " 72,\n",
       " 73,\n",
       " 78,\n",
       " 0,\n",
       " 64,\n",
       " 73,\n",
       " 76,\n",
       " 60,\n",
       " 63,\n",
       " 59,\n",
       " 76,\n",
       " 0,\n",
       " 70,\n",
       " 67,\n",
       " 77,\n",
       " 78,\n",
       " 63,\n",
       " 72,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 0,\n",
       " 64,\n",
       " 73,\n",
       " 76,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 61,\n",
       " 76,\n",
       " 83,\n",
       " 0,\n",
       " 73,\n",
       " 64,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 73,\n",
       " 77,\n",
       " 63,\n",
       " 0,\n",
       " 70,\n",
       " 73,\n",
       " 72,\n",
       " 65,\n",
       " 0,\n",
       " 81,\n",
       " 66,\n",
       " 67,\n",
       " 78,\n",
       " 63,\n",
       " 0,\n",
       " 76,\n",
       " 67,\n",
       " 74,\n",
       " 74,\n",
       " 70,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 0,\n",
       " 81,\n",
       " 59,\n",
       " 80,\n",
       " 63,\n",
       " 77,\n",
       " 105,\n",
       " 62,\n",
       " 76,\n",
       " 59,\n",
       " 65,\n",
       " 65,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 0,\n",
       " 79,\n",
       " 74,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 67,\n",
       " 76,\n",
       " 0,\n",
       " 77,\n",
       " 78,\n",
       " 76,\n",
       " 63,\n",
       " 72,\n",
       " 65,\n",
       " 78,\n",
       " 66,\n",
       " 0,\n",
       " 78,\n",
       " 73,\n",
       " 0,\n",
       " 60,\n",
       " 76,\n",
       " 63,\n",
       " 59,\n",
       " 69,\n",
       " 0,\n",
       " 73,\n",
       " 72,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 77,\n",
       " 79,\n",
       " 70,\n",
       " 70,\n",
       " 63,\n",
       " 72,\n",
       " 0,\n",
       " 60,\n",
       " 63,\n",
       " 59,\n",
       " 61,\n",
       " 66,\n",
       " 0,\n",
       " 73,\n",
       " 64,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 77,\n",
       " 69,\n",
       " 83,\n",
       " 106,\n",
       " 0,\n",
       " 64,\n",
       " 67,\n",
       " 72,\n",
       " 62,\n",
       " 28,\n",
       " 106,\n",
       " 70,\n",
       " 23,\n",
       " 0,\n",
       " 72,\n",
       " 73,\n",
       " 71,\n",
       " 105,\n",
       " 77,\n",
       " 65,\n",
       " 105,\n",
       " 65,\n",
       " 67,\n",
       " 64,\n",
       " 0,\n",
       " 66,\n",
       " 67,\n",
       " 71,\n",
       " 106,\n",
       " 73,\n",
       " 72,\n",
       " 63,\n",
       " 0,\n",
       " 65,\n",
       " 73,\n",
       " 78,\n",
       " 0,\n",
       " 67,\n",
       " 78,\n",
       " 0,\n",
       " 73,\n",
       " 64,\n",
       " 64,\n",
       " 0,\n",
       " 60,\n",
       " 83,\n",
       " 0,\n",
       " 66,\n",
       " 63,\n",
       " 59,\n",
       " 76,\n",
       " 78,\n",
       " 105,\n",
       " 63,\n",
       " 80,\n",
       " 63,\n",
       " 76,\n",
       " 83,\n",
       " 0,\n",
       " 77,\n",
       " 78,\n",
       " 59,\n",
       " 76,\n",
       " 78,\n",
       " 0,\n",
       " 81,\n",
       " 59,\n",
       " 77,\n",
       " 0,\n",
       " 59,\n",
       " 0,\n",
       " 60,\n",
       " 59,\n",
       " 62,\n",
       " 0,\n",
       " 77,\n",
       " 78,\n",
       " 59,\n",
       " 76,\n",
       " 78,\n",
       " 105,\n",
       " 77,\n",
       " 67,\n",
       " 72,\n",
       " 61,\n",
       " 63,\n",
       " 0,\n",
       " 59,\n",
       " 70,\n",
       " 70,\n",
       " 0,\n",
       " 61,\n",
       " 73,\n",
       " 72,\n",
       " 61,\n",
       " 70,\n",
       " 79,\n",
       " 77,\n",
       " 67,\n",
       " 73,\n",
       " 72,\n",
       " 77,\n",
       " 0,\n",
       " 81,\n",
       " 63,\n",
       " 76,\n",
       " 63,\n",
       " 0,\n",
       " 64,\n",
       " 73,\n",
       " 76,\n",
       " 63,\n",
       " 65,\n",
       " 73,\n",
       " 72,\n",
       " 63,\n",
       " 106,\n",
       " 63,\n",
       " 77,\n",
       " 61,\n",
       " 59,\n",
       " 74,\n",
       " 63,\n",
       " 105,\n",
       " 81,\n",
       " 67,\n",
       " 78,\n",
       " 66,\n",
       " 67,\n",
       " 72,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 74,\n",
       " 76,\n",
       " 67,\n",
       " 77,\n",
       " 73,\n",
       " 72,\n",
       " 0,\n",
       " 81,\n",
       " 59,\n",
       " 70,\n",
       " 70,\n",
       " 77,\n",
       " 105,\n",
       " 59,\n",
       " 0,\n",
       " 70,\n",
       " 67,\n",
       " 60,\n",
       " 76,\n",
       " 59,\n",
       " 76,\n",
       " 83,\n",
       " 106,\n",
       " 77,\n",
       " 0,\n",
       " 72,\n",
       " 73,\n",
       " 78,\n",
       " 0,\n",
       " 81,\n",
       " 66,\n",
       " 59,\n",
       " 78,\n",
       " 0,\n",
       " 73,\n",
       " 61,\n",
       " 61,\n",
       " 79,\n",
       " 74,\n",
       " 67,\n",
       " 63,\n",
       " 77,\n",
       " 0,\n",
       " 71,\n",
       " 83,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 73,\n",
       " 79,\n",
       " 65,\n",
       " 66,\n",
       " 78,\n",
       " 77,\n",
       " 0,\n",
       " 59,\n",
       " 78,\n",
       " 0,\n",
       " 74,\n",
       " 76,\n",
       " 63,\n",
       " 77,\n",
       " 63,\n",
       " 72,\n",
       " 78,\n",
       " 105,\n",
       " 72,\n",
       " 73,\n",
       " 76,\n",
       " 0,\n",
       " 81,\n",
       " 66,\n",
       " 83,\n",
       " 0,\n",
       " 67,\n",
       " 0,\n",
       " 77,\n",
       " 63,\n",
       " 72,\n",
       " 78,\n",
       " 0,\n",
       " 64,\n",
       " 73,\n",
       " 76,\n",
       " 0,\n",
       " 83,\n",
       " 73,\n",
       " 79,\n",
       " 0,\n",
       " 71,\n",
       " 63,\n",
       " 77,\n",
       " 77,\n",
       " 63,\n",
       " 76,\n",
       " 0,\n",
       " 71,\n",
       " 67,\n",
       " 61,\n",
       " 66,\n",
       " 63,\n",
       " 70,\n",
       " 63,\n",
       " 106,\n",
       " 81,\n",
       " 66,\n",
       " 67,\n",
       " 78,\n",
       " 63,\n",
       " 0,\n",
       " 71,\n",
       " 59,\n",
       " 77,\n",
       " 69,\n",
       " 105,\n",
       " 60,\n",
       " 63,\n",
       " 61,\n",
       " 59,\n",
       " 79,\n",
       " 77,\n",
       " 63,\n",
       " 0,\n",
       " 73,\n",
       " 64,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 74,\n",
       " 73,\n",
       " 70,\n",
       " 70,\n",
       " 79,\n",
       " 78,\n",
       " 67,\n",
       " 73,\n",
       " 72,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 105,\n",
       " 59,\n",
       " 0,\n",
       " 62,\n",
       " 59,\n",
       " 83,\n",
       " 0,\n",
       " 71,\n",
       " 73,\n",
       " 73,\n",
       " 72,\n",
       " 106,\n",
       " 74,\n",
       " 74,\n",
       " 70,\n",
       " 63,\n",
       " 77,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 105,\n",
       " 64,\n",
       " 63,\n",
       " 63,\n",
       " 70,\n",
       " 0,\n",
       " 73,\n",
       " 64,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 74,\n",
       " 59,\n",
       " 76,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 0,\n",
       " 60,\n",
       " 70,\n",
       " 59,\n",
       " 62,\n",
       " 63,\n",
       " 105,\n",
       " 60,\n",
       " 63,\n",
       " 78,\n",
       " 81,\n",
       " 63,\n",
       " 63,\n",
       " 72,\n",
       " 0,\n",
       " 71,\n",
       " 83,\n",
       " 0,\n",
       " 64,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 63,\n",
       " 76,\n",
       " 77,\n",
       " 106,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 59,\n",
       " 70,\n",
       " 66,\n",
       " 59,\n",
       " 71,\n",
       " 60,\n",
       " 76,\n",
       " 59,\n",
       " 105,\n",
       " 79,\n",
       " 72,\n",
       " 62,\n",
       " 63,\n",
       " 76,\n",
       " 0,\n",
       " 81,\n",
       " 66,\n",
       " 73,\n",
       " 77,\n",
       " 63,\n",
       " 0,\n",
       " 78,\n",
       " 73,\n",
       " 81,\n",
       " 63,\n",
       " 76,\n",
       " 77,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 65,\n",
       " 83,\n",
       " 74,\n",
       " 77,\n",
       " 83,\n",
       " 0,\n",
       " 61,\n",
       " 59,\n",
       " 71,\n",
       " 74,\n",
       " 0,\n",
       " 81,\n",
       " 59,\n",
       " 77,\n",
       " 0,\n",
       " 74,\n",
       " 67,\n",
       " 78,\n",
       " 61,\n",
       " 66,\n",
       " 63,\n",
       " 62,\n",
       " 106,\n",
       " 83,\n",
       " 105,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 74,\n",
       " 59,\n",
       " 67,\n",
       " 72,\n",
       " 105,\n",
       " 83,\n",
       " 73,\n",
       " 79,\n",
       " 0,\n",
       " 81,\n",
       " 59,\n",
       " 69,\n",
       " 63,\n",
       " 0,\n",
       " 78,\n",
       " 73,\n",
       " 0,\n",
       " 67,\n",
       " 77,\n",
       " 0,\n",
       " 72,\n",
       " 73,\n",
       " 78,\n",
       " 0,\n",
       " 83,\n",
       " 73,\n",
       " 79,\n",
       " 76,\n",
       " 77,\n",
       " 106,\n",
       " 63,\n",
       " 80,\n",
       " 63,\n",
       " 28,\n",
       " 105,\n",
       " 60,\n",
       " 76,\n",
       " 59,\n",
       " 72,\n",
       " 62,\n",
       " 0,\n",
       " 72,\n",
       " 63,\n",
       " 81,\n",
       " 0,\n",
       " 77,\n",
       " 63,\n",
       " 63,\n",
       " 62,\n",
       " 105,\n",
       " 67,\n",
       " 72,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 64,\n",
       " 63,\n",
       " 63,\n",
       " 62,\n",
       " 63,\n",
       " 76,\n",
       " 106,\n",
       " 76,\n",
       " 83,\n",
       " 105,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 64,\n",
       " 67,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 0,\n",
       " 65,\n",
       " 59,\n",
       " 76,\n",
       " 62,\n",
       " 63,\n",
       " 72,\n",
       " 0,\n",
       " 77,\n",
       " 63,\n",
       " 63,\n",
       " 62,\n",
       " 77,\n",
       " 0,\n",
       " 62,\n",
       " 67,\n",
       " 77,\n",
       " 74,\n",
       " 70,\n",
       " 59,\n",
       " 83,\n",
       " 105,\n",
       " 59,\n",
       " 78,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 0,\n",
       " 66,\n",
       " 59,\n",
       " 76,\n",
       " 62,\n",
       " 81,\n",
       " 59,\n",
       " 76,\n",
       " 63,\n",
       " 0,\n",
       " 77,\n",
       " 78,\n",
       " 73,\n",
       " 76,\n",
       " 63,\n",
       " 106,\n",
       " 70,\n",
       " 70,\n",
       " 73,\n",
       " 81,\n",
       " 59,\n",
       " 72,\n",
       " 61,\n",
       " 63,\n",
       " 0,\n",
       " 81,\n",
       " 59,\n",
       " 77,\n",
       " 0,\n",
       " 78,\n",
       " 63,\n",
       " 72,\n",
       " 105,\n",
       " 78,\n",
       " 66,\n",
       " 73,\n",
       " 79,\n",
       " 77,\n",
       " 59,\n",
       " 72,\n",
       " 62,\n",
       " 0,\n",
       " 61,\n",
       " 59,\n",
       " 77,\n",
       " 66,\n",
       " 24,\n",
       " 0,\n",
       " 48,\n",
       " 66,\n",
       " 76,\n",
       " 63,\n",
       " 63,\n",
       " 0,\n",
       " 78,\n",
       " 67,\n",
       " 71,\n",
       " 63,\n",
       " 77,\n",
       " 0,\n",
       " 59,\n",
       " 0,\n",
       " 62,\n",
       " 59,\n",
       " 83,\n",
       " 0,\n",
       " 78,\n",
       " 66,\n",
       " 63,\n",
       " 105,\n",
       " 33,\n",
       " 71,\n",
       " 74,\n",
       " 63,\n",
       " 76,\n",
       " 73,\n",
       " 76,\n",
       " 0,\n",
       " 61,\n",
       " 59,\n",
       " 71,\n",
       " ...]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "#X = np.reshape(poemX, (n_patterns, seq_length, n_poems))\n",
    "# normalize\n",
    "X = np.array([np.array([char / float(n_chars) for char in seq]) for poem in poemX for seq in poem])\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "# one hot encode the output variable\n",
    "y = to_categorical([nextchar for poem in poemY for nextchar in poem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "#X = np.reshape(poemX, (n_patterns, seq_length, n_poems))\n",
    "# normalize\n",
    "X = np.reshape(X, (len(corpusX), seq_length, 1))\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(corpusY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598178, 10, 1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1598178/1598178 [==============================] - 277s 173us/step - loss: 3.0729\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.07295, saving model to letter-weights-01-3.0729.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17e7e3380c8>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"letter-weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=1, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poemchar(index):\n",
    "    char = int_to_char[index]\n",
    "    if char == '↕':\n",
    "        char = '\\n'\n",
    "    elif char == '◘':\n",
    "        char = '' # represent end of poem\n",
    "    return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max starte0\n",
      " 0\n",
      " 0\n",
      " \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "start = np.random.randint(0, len(poemX)-1)\n",
    "while start == endpoem_charindex: # don't start with end of the poem\n",
    "    start = np.random.randint(0, len(poemX)-1)\n",
    "    \n",
    "pattern = poemX[start][0]\n",
    "[print(poemchar(char), end='') for char in pattern]\n",
    "# generate characters\n",
    "for i in range(3):\n",
    "    x = np.reshape([char / float(n_vocab) for char in pattern], (1, len(pattern), 1))\n",
    "    #print(x)\n",
    "    prediction = model.predict(x, verbose=0) * float(n_vocab)\n",
    "    #print(prediction)\n",
    "    index = np.argmax(prediction)\n",
    "    print(index)\n",
    "    result = poemchar(index)\n",
    "    \n",
    "    if result == '':\n",
    "        break;\n",
    "    \n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(result, end='')\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's.... kinda terrible. Let's use words instead of letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>01</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>12a</th>\n",
       "      <th>12th</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zor</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuleika</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zushio</th>\n",
       "      <th>émeutes</th>\n",
       "      <th>équilibre</th>\n",
       "      <th>ēn</th>\n",
       "      <th>ēng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25128 rows × 26228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  01  10  100  11  11th  12  12a  12th  13  ...  zoom  zor  zucchini  \\\n",
       "3609    0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "12344   0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "12027   0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "4696    0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "23119   0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "...    ..  ..  ..  ...  ..   ...  ..  ...   ...  ..  ...   ...  ...       ...   \n",
       "29802   0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "5390    0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "860     0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "15795   0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "23654   0   0   0    0   0     0   0    0     0   0  ...     0    0         0   \n",
       "\n",
       "       zuleika  zulu  zushio  émeutes  équilibre  ēn  ēng  \n",
       "3609         0     0       0        0          0   0    0  \n",
       "12344        0     0       0        0          0   0    0  \n",
       "12027        0     0       0        0          0   0    0  \n",
       "4696         0     0       0        0          0   0    0  \n",
       "23119        0     0       0        0          0   0    0  \n",
       "...        ...   ...     ...      ...        ...  ..  ...  \n",
       "29802        0     0       0        0          0   0    0  \n",
       "5390         0     0       0        0          0   0    0  \n",
       "860          0     0       0        0          0   0    0  \n",
       "15795        0     0       0        0          0   0    0  \n",
       "23654        0     0       0        0          0   0    0  \n",
       "\n",
       "[25128 rows x 26228 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount = CountVectorizer(lowercase=False)\n",
    "\n",
    "X_wc = wordcount.fit_transform(haikus_train_df['text_withtokens'].map(lambda x: ' '.join(x)))\n",
    "\n",
    "pd.DataFrame(X_wc.toarray(), columns=wordcount.get_feature_names(), index=haikus_train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "value_counts not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-f6493d1f9389>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_wc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: value_counts not found"
     ]
    }
   ],
   "source": [
    "X_wc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words:  524930\n",
      "Total Vocab:  41965\n"
     ]
    }
   ],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "corpuswords_raw = flatten(list(haikus_notwitter_df['text_withtokens']))\n",
    "\n",
    "words = sorted(set(corpuswords_raw))\n",
    "word_to_int = dict((w, i) for i, w in enumerate(words))\n",
    "\n",
    "n_words = len(corpuswords_raw)\n",
    "n_vocab_words = len(words)\n",
    "print(\"Total Words: \", n_words)\n",
    "print(\"Total Vocab: \", n_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-5d87a978443b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwordX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwordY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_words\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mseq_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpuswords_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mseq_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpuswords_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_words' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 2\n",
    "wordX = []\n",
    "wordY = []\n",
    "for i in range(0, n_words - seq_length, 1):\n",
    "    seq_in = corpuswords_raw[i:i + seq_length]\n",
    "    seq_out = corpuswords_raw[i + seq_length]\n",
    "    dataX.append([word_to_int[word] for word in seq_in])\n",
    "    dataY.append(word_to_int[seq_out])\n",
    "n_wordpatterns = len(wordX)\n",
    "print(\"Total Patterns: \", n_wordpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-a8df23e33121>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_vocab_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# one hot encode the output variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2666\u001b[0m     \"\"\"\n\u001b[0;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[1;32m-> 2668\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(wordX, (n_wordpatterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab_words)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(wordY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vi_ci\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "2317498/2317498 [==============================] - 3132s 1ms/step - loss: 2.6616\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.66164, saving model to weights-improvement-01-2.6616.hdf5\n",
      "Epoch 2/20\n",
      "2317498/2317498 [==============================] - 3145s 1ms/step - loss: 2.3491\n",
      "\n",
      "Epoch 00002: loss improved from 2.66164 to 2.34912, saving model to weights-improvement-02-2.3491.hdf5\n",
      "Epoch 3/20\n",
      "2317498/2317498 [==============================] - 3117s 1ms/step - loss: 2.2023\n",
      "\n",
      "Epoch 00003: loss improved from 2.34912 to 2.20226, saving model to weights-improvement-03-2.2023.hdf5\n",
      "Epoch 4/20\n",
      "2317498/2317498 [==============================] - 3103s 1ms/step - loss: 2.1132\n",
      "\n",
      "Epoch 00004: loss improved from 2.20226 to 2.11321, saving model to weights-improvement-04-2.1132.hdf5\n",
      "Epoch 5/20\n",
      "2317498/2317498 [==============================] - 3102s 1ms/step - loss: 2.0521\n",
      "\n",
      "Epoch 00005: loss improved from 2.11321 to 2.05213, saving model to weights-improvement-05-2.0521.hdf5\n",
      "Epoch 6/20\n",
      "2317498/2317498 [==============================] - 3098s 1ms/step - loss: 2.0051\n",
      "\n",
      "Epoch 00006: loss improved from 2.05213 to 2.00513, saving model to weights-improvement-06-2.0051.hdf5\n",
      "Epoch 7/20\n",
      "2317498/2317498 [==============================] - 3099s 1ms/step - loss: 1.9691\n",
      "\n",
      "Epoch 00007: loss improved from 2.00513 to 1.96914, saving model to weights-improvement-07-1.9691.hdf5\n",
      "Epoch 8/20\n",
      "2317498/2317498 [==============================] - 3099s 1ms/step - loss: 1.9404\n",
      "\n",
      "Epoch 00008: loss improved from 1.96914 to 1.94036, saving model to weights-improvement-08-1.9404.hdf5\n",
      "Epoch 9/20\n",
      "2317498/2317498 [==============================] - 3090s 1ms/step - loss: 1.9164\n",
      "\n",
      "Epoch 00009: loss improved from 1.94036 to 1.91641, saving model to weights-improvement-09-1.9164.hdf5\n",
      "Epoch 10/20\n",
      "2317498/2317498 [==============================] - 3102s 1ms/step - loss: 1.8969\n",
      "\n",
      "Epoch 00010: loss improved from 1.91641 to 1.89692, saving model to weights-improvement-10-1.8969.hdf5\n",
      "Epoch 11/20\n",
      "2317498/2317498 [==============================] - 3134s 1ms/step - loss: 1.8796\n",
      "\n",
      "Epoch 00011: loss improved from 1.89692 to 1.87956, saving model to weights-improvement-11-1.8796.hdf5\n",
      "Epoch 12/20\n",
      "2317498/2317498 [==============================] - 3147s 1ms/step - loss: 2.4950\n",
      "\n",
      "Epoch 00012: loss did not improve from 1.87956\n",
      "Epoch 13/20\n",
      "2317498/2317498 [==============================] - 3128s 1ms/step - loss: 2.2318\n",
      "\n",
      "Epoch 00013: loss did not improve from 1.87956\n",
      "Epoch 14/20\n",
      "2317498/2317498 [==============================] - 3148s 1ms/step - loss: 2.1011\n",
      "\n",
      "Epoch 00014: loss did not improve from 1.87956\n",
      "Epoch 15/20\n",
      "2317498/2317498 [==============================] - 3113s 1ms/step - loss: 2.0327\n",
      "\n",
      "Epoch 00015: loss did not improve from 1.87956\n",
      "Epoch 16/20\n",
      "2317498/2317498 [==============================] - 3104s 1ms/step - loss: 1.9880\n",
      "\n",
      "Epoch 00016: loss did not improve from 1.87956\n",
      "Epoch 17/20\n",
      "2317498/2317498 [==============================] - 3157s 1ms/step - loss: 1.9540\n",
      "\n",
      "Epoch 00017: loss did not improve from 1.87956\n",
      "Epoch 18/20\n",
      "2317498/2317498 [==============================] - 3164s 1ms/step - loss: 1.9282\n",
      "\n",
      "Epoch 00018: loss did not improve from 1.87956\n",
      "Epoch 19/20\n",
      "2317498/2317498 [==============================] - 3166s 1ms/step - loss: 1.9060\n",
      "\n",
      "Epoch 00019: loss did not improve from 1.87956\n",
      "Epoch 20/20\n",
      "2317498/2317498 [==============================] - 3167s 1ms/step - loss: 1.8872\n",
      "\n",
      "Epoch 00020: loss did not improve from 1.87956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22a239b3c48>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he sound of the sain\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    \n",
    "    if result == '↕':\n",
    "        result = '\\n'\n",
    "    elif result == '◘':\n",
    "        break;\n",
    "    \n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(result, end='')\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling\n",
    "## 1. From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, Doc2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23462"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorise with TF-IDF\n",
    "tv = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "haiku_train_tv = tv.fit_transform(haikus_train_df['text_clean'])\n",
    "haiku_test_tv  = tv.transform(haikus_test_df['text_clean'])\n",
    "\n",
    "len(tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160557"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv2 = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "\n",
    "haiku_train_tv2 = tv2.fit_transform(haikus_train_df['text_clean'])\n",
    "haiku_test_tv2  = tv2.transform(haikus_test_df['text_clean'])\n",
    "\n",
    "len(tv2.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23.5k features for unigram, explodes to 160.6k features with bigrams\n",
    "\n",
    "Let's see what basic topic modelling comes up with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(model, feature_names, n_top_words):\n",
    "    topic_list = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        word_list = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topic_list.append(word_list)\n",
    "\n",
    "    return topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_0</th>\n",
       "      <td>thy</td>\n",
       "      <td>thou</td>\n",
       "      <td>thee</td>\n",
       "      <td>shall</td>\n",
       "      <td>come</td>\n",
       "      <td>god</td>\n",
       "      <td>heart</td>\n",
       "      <td>man</td>\n",
       "      <td>said</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>moon</td>\n",
       "      <td>harvest</td>\n",
       "      <td>crescent</td>\n",
       "      <td>new</td>\n",
       "      <td>half</td>\n",
       "      <td>window</td>\n",
       "      <td>just</td>\n",
       "      <td>rising</td>\n",
       "      <td>puddle</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>rain</td>\n",
       "      <td>sound</td>\n",
       "      <td>scent</td>\n",
       "      <td>smell</td>\n",
       "      <td>cold</td>\n",
       "      <td>window</td>\n",
       "      <td>soft</td>\n",
       "      <td>garden</td>\n",
       "      <td>steady</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_3</th>\n",
       "      <td>night</td>\n",
       "      <td>stars</td>\n",
       "      <td>cold</td>\n",
       "      <td>late</td>\n",
       "      <td>moonless</td>\n",
       "      <td>starry</td>\n",
       "      <td>dark</td>\n",
       "      <td>sleepless</td>\n",
       "      <td>sleep</td>\n",
       "      <td>window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_4</th>\n",
       "      <td>day</td>\n",
       "      <td>year</td>\n",
       "      <td>mother</td>\n",
       "      <td>valentine</td>\n",
       "      <td>memorial</td>\n",
       "      <td>warm</td>\n",
       "      <td>new</td>\n",
       "      <td>hot</td>\n",
       "      <td>rainy</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_5</th>\n",
       "      <td>morning</td>\n",
       "      <td>fog</td>\n",
       "      <td>coffee</td>\n",
       "      <td>mist</td>\n",
       "      <td>early</td>\n",
       "      <td>cold</td>\n",
       "      <td>cup</td>\n",
       "      <td>haze</td>\n",
       "      <td>sunday</td>\n",
       "      <td>frost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_6</th>\n",
       "      <td>summer</td>\n",
       "      <td>end</td>\n",
       "      <td>indian</td>\n",
       "      <td>late</td>\n",
       "      <td>heat</td>\n",
       "      <td>solstice</td>\n",
       "      <td>sound</td>\n",
       "      <td>river</td>\n",
       "      <td>evening</td>\n",
       "      <td>dusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_7</th>\n",
       "      <td>autumn</td>\n",
       "      <td>leaves</td>\n",
       "      <td>falling</td>\n",
       "      <td>evening</td>\n",
       "      <td>equinox</td>\n",
       "      <td>chill</td>\n",
       "      <td>dusk</td>\n",
       "      <td>deep</td>\n",
       "      <td>sunset</td>\n",
       "      <td>fallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_8</th>\n",
       "      <td>winter</td>\n",
       "      <td>solstice</td>\n",
       "      <td>stars</td>\n",
       "      <td>deep</td>\n",
       "      <td>cold</td>\n",
       "      <td>late</td>\n",
       "      <td>cat</td>\n",
       "      <td>train</td>\n",
       "      <td>comes</td>\n",
       "      <td>hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_9</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>man</td>\n",
       "      <td>year</td>\n",
       "      <td>woman</td>\n",
       "      <td>dog</td>\n",
       "      <td>days</td>\n",
       "      <td>wall</td>\n",
       "      <td>leaves</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_10</th>\n",
       "      <td>sky</td>\n",
       "      <td>blue</td>\n",
       "      <td>clouds</td>\n",
       "      <td>white</td>\n",
       "      <td>stars</td>\n",
       "      <td>sea</td>\n",
       "      <td>eyes</td>\n",
       "      <td>high</td>\n",
       "      <td>color</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_11</th>\n",
       "      <td>light</td>\n",
       "      <td>evening</td>\n",
       "      <td>darkness</td>\n",
       "      <td>way</td>\n",
       "      <td>dark</td>\n",
       "      <td>dawn</td>\n",
       "      <td>candle</td>\n",
       "      <td>red</td>\n",
       "      <td>eyes</td>\n",
       "      <td>sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_12</th>\n",
       "      <td>wind</td>\n",
       "      <td>sound</td>\n",
       "      <td>cold</td>\n",
       "      <td>tree</td>\n",
       "      <td>blowing</td>\n",
       "      <td>north</td>\n",
       "      <td>trees</td>\n",
       "      <td>chill</td>\n",
       "      <td>blows</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_13</th>\n",
       "      <td>snow</td>\n",
       "      <td>white</td>\n",
       "      <td>falling</td>\n",
       "      <td>fresh</td>\n",
       "      <td>new</td>\n",
       "      <td>face</td>\n",
       "      <td>covered</td>\n",
       "      <td>window</td>\n",
       "      <td>melting</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_14</th>\n",
       "      <td>love</td>\n",
       "      <td>oh</td>\n",
       "      <td>song</td>\n",
       "      <td>heart</td>\n",
       "      <td>loved</td>\n",
       "      <td>said</td>\n",
       "      <td>dear</td>\n",
       "      <td>mother</td>\n",
       "      <td>kiss</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_15</th>\n",
       "      <td>spring</td>\n",
       "      <td>breeze</td>\n",
       "      <td>early</td>\n",
       "      <td>bird</td>\n",
       "      <td>flowers</td>\n",
       "      <td>cleaning</td>\n",
       "      <td>late</td>\n",
       "      <td>dawn</td>\n",
       "      <td>green</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_16</th>\n",
       "      <td>sun</td>\n",
       "      <td>shadow</td>\n",
       "      <td>red</td>\n",
       "      <td>bright</td>\n",
       "      <td>rising</td>\n",
       "      <td>low</td>\n",
       "      <td>earth</td>\n",
       "      <td>face</td>\n",
       "      <td>high</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_17</th>\n",
       "      <td>long</td>\n",
       "      <td>time</td>\n",
       "      <td>road</td>\n",
       "      <td>ago</td>\n",
       "      <td>years</td>\n",
       "      <td>shadows</td>\n",
       "      <td>shadow</td>\n",
       "      <td>home</td>\n",
       "      <td>song</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_18</th>\n",
       "      <td>like</td>\n",
       "      <td>world</td>\n",
       "      <td>water</td>\n",
       "      <td>heart</td>\n",
       "      <td>sea</td>\n",
       "      <td>red</td>\n",
       "      <td>air</td>\n",
       "      <td>little</td>\n",
       "      <td>just</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_19</th>\n",
       "      <td>know</td>\n",
       "      <td>don</td>\n",
       "      <td>did</td>\n",
       "      <td>time</td>\n",
       "      <td>think</td>\n",
       "      <td>mother</td>\n",
       "      <td>does</td>\n",
       "      <td>just</td>\n",
       "      <td>father</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_0    word_1    word_2     word_3    word_4    word_5   word_6  \\\n",
       "topic_0       thy      thou      thee      shall      come       god    heart   \n",
       "topic_1      moon   harvest  crescent        new      half    window     just   \n",
       "topic_2      rain     sound     scent      smell      cold    window     soft   \n",
       "topic_3     night     stars      cold       late  moonless    starry     dark   \n",
       "topic_4       day      year    mother  valentine  memorial      warm      new   \n",
       "topic_5   morning       fog    coffee       mist     early      cold      cup   \n",
       "topic_6    summer       end    indian       late      heat  solstice    sound   \n",
       "topic_7    autumn    leaves   falling    evening   equinox     chill     dusk   \n",
       "topic_8    winter  solstice     stars       deep      cold      late      cat   \n",
       "topic_9       old       new       man       year     woman       dog     days   \n",
       "topic_10      sky      blue    clouds      white     stars       sea     eyes   \n",
       "topic_11    light   evening  darkness        way      dark      dawn   candle   \n",
       "topic_12     wind     sound      cold       tree   blowing     north    trees   \n",
       "topic_13     snow     white   falling      fresh       new      face  covered   \n",
       "topic_14     love        oh      song      heart     loved      said     dear   \n",
       "topic_15   spring    breeze     early       bird   flowers  cleaning     late   \n",
       "topic_16      sun    shadow       red     bright    rising       low    earth   \n",
       "topic_17     long      time      road        ago     years   shadows   shadow   \n",
       "topic_18     like     world     water      heart       sea       red      air   \n",
       "topic_19     know       don       did       time     think    mother     does   \n",
       "\n",
       "             word_7   word_8  word_9  \n",
       "topic_0         man     said    life  \n",
       "topic_1      rising   puddle    cold  \n",
       "topic_2      garden   steady   heavy  \n",
       "topic_3   sleepless    sleep  window  \n",
       "topic_4         hot    rainy     end  \n",
       "topic_5        haze   sunday   frost  \n",
       "topic_6       river  evening    dusk  \n",
       "topic_7        deep   sunset  fallen  \n",
       "topic_8       train    comes   hands  \n",
       "topic_9        wall   leaves   young  \n",
       "topic_10       high    color   clear  \n",
       "topic_11        red     eyes  sunset  \n",
       "topic_12      chill    blows    home  \n",
       "topic_13     window  melting   black  \n",
       "topic_14     mother     kiss    true  \n",
       "topic_15       dawn    green     cat  \n",
       "topic_16       face     high   white  \n",
       "topic_17       home     song     way  \n",
       "topic_18     little     just    cold  \n",
       "topic_19       just   father    want  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(20, random_state=RANDOM)\n",
    "nmf_topic = nmf_model.fit_transform(haiku_train_tv)\n",
    "pd.DataFrame(top_words(nmf_model, tv.get_feature_names(), 10)).add_prefix('word_').rename('topic_{}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_0</th>\n",
       "      <td>rain</td>\n",
       "      <td>winter rain</td>\n",
       "      <td>spring rain</td>\n",
       "      <td>summer rain</td>\n",
       "      <td>autumn rain</td>\n",
       "      <td>sound</td>\n",
       "      <td>scent</td>\n",
       "      <td>smell</td>\n",
       "      <td>night rain</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>moon</td>\n",
       "      <td>harvest</td>\n",
       "      <td>harvest moon</td>\n",
       "      <td>crescent</td>\n",
       "      <td>crescent moon</td>\n",
       "      <td>half</td>\n",
       "      <td>new moon</td>\n",
       "      <td>half moon</td>\n",
       "      <td>day moon</td>\n",
       "      <td>window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>thy</td>\n",
       "      <td>thou</td>\n",
       "      <td>shall</td>\n",
       "      <td>thee</td>\n",
       "      <td>like</td>\n",
       "      <td>heart</td>\n",
       "      <td>god</td>\n",
       "      <td>life</td>\n",
       "      <td>said</td>\n",
       "      <td>dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_3</th>\n",
       "      <td>night</td>\n",
       "      <td>long</td>\n",
       "      <td>winter night</td>\n",
       "      <td>moonless night</td>\n",
       "      <td>moonless</td>\n",
       "      <td>cold</td>\n",
       "      <td>late night</td>\n",
       "      <td>stars</td>\n",
       "      <td>late</td>\n",
       "      <td>starry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_4</th>\n",
       "      <td>day</td>\n",
       "      <td>long</td>\n",
       "      <td>valentine day</td>\n",
       "      <td>valentine</td>\n",
       "      <td>mother</td>\n",
       "      <td>day day</td>\n",
       "      <td>memorial day</td>\n",
       "      <td>memorial</td>\n",
       "      <td>mother day</td>\n",
       "      <td>warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_5</th>\n",
       "      <td>morning</td>\n",
       "      <td>fog</td>\n",
       "      <td>morning fog</td>\n",
       "      <td>morning sun</td>\n",
       "      <td>spring morning</td>\n",
       "      <td>coffee</td>\n",
       "      <td>early</td>\n",
       "      <td>early morning</td>\n",
       "      <td>mist</td>\n",
       "      <td>winter morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_6</th>\n",
       "      <td>summer</td>\n",
       "      <td>end</td>\n",
       "      <td>summer end</td>\n",
       "      <td>indian summer</td>\n",
       "      <td>indian</td>\n",
       "      <td>late</td>\n",
       "      <td>summer rain</td>\n",
       "      <td>late summer</td>\n",
       "      <td>heat</td>\n",
       "      <td>end summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_7</th>\n",
       "      <td>winter</td>\n",
       "      <td>winter rain</td>\n",
       "      <td>winter night</td>\n",
       "      <td>solstice</td>\n",
       "      <td>winter solstice</td>\n",
       "      <td>stars</td>\n",
       "      <td>winter stars</td>\n",
       "      <td>deep</td>\n",
       "      <td>deep winter</td>\n",
       "      <td>winter morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_8</th>\n",
       "      <td>leaves</td>\n",
       "      <td>falling</td>\n",
       "      <td>fallen</td>\n",
       "      <td>fallen leaves</td>\n",
       "      <td>falling leaves</td>\n",
       "      <td>autumn leaves</td>\n",
       "      <td>red</td>\n",
       "      <td>fall</td>\n",
       "      <td>maple</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_9</th>\n",
       "      <td>sky</td>\n",
       "      <td>blue</td>\n",
       "      <td>blue sky</td>\n",
       "      <td>clouds</td>\n",
       "      <td>white</td>\n",
       "      <td>sea</td>\n",
       "      <td>stars</td>\n",
       "      <td>high</td>\n",
       "      <td>color</td>\n",
       "      <td>eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_10</th>\n",
       "      <td>old</td>\n",
       "      <td>man</td>\n",
       "      <td>old man</td>\n",
       "      <td>woman</td>\n",
       "      <td>dog</td>\n",
       "      <td>year old</td>\n",
       "      <td>wall</td>\n",
       "      <td>days</td>\n",
       "      <td>young</td>\n",
       "      <td>old pond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_11</th>\n",
       "      <td>spring</td>\n",
       "      <td>wind</td>\n",
       "      <td>spring wind</td>\n",
       "      <td>spring rain</td>\n",
       "      <td>long</td>\n",
       "      <td>spring morning</td>\n",
       "      <td>autumn wind</td>\n",
       "      <td>breeze</td>\n",
       "      <td>cold</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_12</th>\n",
       "      <td>come</td>\n",
       "      <td>home</td>\n",
       "      <td>come come</td>\n",
       "      <td>let</td>\n",
       "      <td>world</td>\n",
       "      <td>come die</td>\n",
       "      <td>word</td>\n",
       "      <td>ll</td>\n",
       "      <td>come home</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_13</th>\n",
       "      <td>light</td>\n",
       "      <td>evening</td>\n",
       "      <td>way</td>\n",
       "      <td>darkness</td>\n",
       "      <td>dawn</td>\n",
       "      <td>candle</td>\n",
       "      <td>dark</td>\n",
       "      <td>morning light</td>\n",
       "      <td>red</td>\n",
       "      <td>sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_14</th>\n",
       "      <td>know</td>\n",
       "      <td>did</td>\n",
       "      <td>don</td>\n",
       "      <td>did know</td>\n",
       "      <td>don know</td>\n",
       "      <td>know know</td>\n",
       "      <td>does</td>\n",
       "      <td>time</td>\n",
       "      <td>think</td>\n",
       "      <td>mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_15</th>\n",
       "      <td>love</td>\n",
       "      <td>love love</td>\n",
       "      <td>oh</td>\n",
       "      <td>song</td>\n",
       "      <td>loved</td>\n",
       "      <td>kiss</td>\n",
       "      <td>oh love</td>\n",
       "      <td>dear</td>\n",
       "      <td>true</td>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_16</th>\n",
       "      <td>snow</td>\n",
       "      <td>white</td>\n",
       "      <td>fresh</td>\n",
       "      <td>falling</td>\n",
       "      <td>fresh snow</td>\n",
       "      <td>window</td>\n",
       "      <td>melting</td>\n",
       "      <td>falling snow</td>\n",
       "      <td>face</td>\n",
       "      <td>covered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_17</th>\n",
       "      <td>autumn</td>\n",
       "      <td>autumn rain</td>\n",
       "      <td>autumn wind</td>\n",
       "      <td>autumn leaves</td>\n",
       "      <td>chill</td>\n",
       "      <td>equinox</td>\n",
       "      <td>autumn chill</td>\n",
       "      <td>evening</td>\n",
       "      <td>autumn equinox</td>\n",
       "      <td>sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_18</th>\n",
       "      <td>new</td>\n",
       "      <td>year</td>\n",
       "      <td>new year</td>\n",
       "      <td>eve</td>\n",
       "      <td>year day</td>\n",
       "      <td>year eve</td>\n",
       "      <td>new moon</td>\n",
       "      <td>time</td>\n",
       "      <td>home</td>\n",
       "      <td>year end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_19</th>\n",
       "      <td>sun</td>\n",
       "      <td>shadow</td>\n",
       "      <td>morning sun</td>\n",
       "      <td>autumn sun</td>\n",
       "      <td>red</td>\n",
       "      <td>winter sun</td>\n",
       "      <td>bright</td>\n",
       "      <td>spring sun</td>\n",
       "      <td>rising</td>\n",
       "      <td>sun bright</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_0       word_1         word_2          word_3  \\\n",
       "topic_0      rain  winter rain    spring rain     summer rain   \n",
       "topic_1      moon      harvest   harvest moon        crescent   \n",
       "topic_2       thy         thou          shall            thee   \n",
       "topic_3     night         long   winter night  moonless night   \n",
       "topic_4       day         long  valentine day       valentine   \n",
       "topic_5   morning          fog    morning fog     morning sun   \n",
       "topic_6    summer          end     summer end   indian summer   \n",
       "topic_7    winter  winter rain   winter night        solstice   \n",
       "topic_8    leaves      falling         fallen   fallen leaves   \n",
       "topic_9       sky         blue       blue sky          clouds   \n",
       "topic_10      old          man        old man           woman   \n",
       "topic_11   spring         wind    spring wind     spring rain   \n",
       "topic_12     come         home      come come             let   \n",
       "topic_13    light      evening            way        darkness   \n",
       "topic_14     know          did            don        did know   \n",
       "topic_15     love    love love             oh            song   \n",
       "topic_16     snow        white          fresh         falling   \n",
       "topic_17   autumn  autumn rain    autumn wind   autumn leaves   \n",
       "topic_18      new         year       new year             eve   \n",
       "topic_19      sun       shadow    morning sun      autumn sun   \n",
       "\n",
       "                   word_4          word_5        word_6         word_7  \\\n",
       "topic_0       autumn rain           sound         scent          smell   \n",
       "topic_1     crescent moon            half      new moon      half moon   \n",
       "topic_2              like           heart           god           life   \n",
       "topic_3          moonless            cold    late night          stars   \n",
       "topic_4            mother         day day  memorial day       memorial   \n",
       "topic_5    spring morning          coffee         early  early morning   \n",
       "topic_6            indian            late   summer rain    late summer   \n",
       "topic_7   winter solstice           stars  winter stars           deep   \n",
       "topic_8    falling leaves   autumn leaves           red           fall   \n",
       "topic_9             white             sea         stars           high   \n",
       "topic_10              dog        year old          wall           days   \n",
       "topic_11             long  spring morning   autumn wind         breeze   \n",
       "topic_12            world        come die          word             ll   \n",
       "topic_13             dawn          candle          dark  morning light   \n",
       "topic_14         don know       know know          does           time   \n",
       "topic_15            loved            kiss       oh love           dear   \n",
       "topic_16       fresh snow          window       melting   falling snow   \n",
       "topic_17            chill         equinox  autumn chill        evening   \n",
       "topic_18         year day        year eve      new moon           time   \n",
       "topic_19              red      winter sun        bright     spring sun   \n",
       "\n",
       "                  word_8          word_9  \n",
       "topic_0       night rain            cold  \n",
       "topic_1         day moon          window  \n",
       "topic_2             said            dead  \n",
       "topic_3             late          starry  \n",
       "topic_4       mother day            warm  \n",
       "topic_5             mist  winter morning  \n",
       "topic_6             heat      end summer  \n",
       "topic_7      deep winter  winter morning  \n",
       "topic_8            maple          yellow  \n",
       "topic_9            color            eyes  \n",
       "topic_10           young        old pond  \n",
       "topic_11            cold            tree  \n",
       "topic_12       come home             end  \n",
       "topic_13             red          sunset  \n",
       "topic_14           think          mother  \n",
       "topic_15            true            knew  \n",
       "topic_16            face         covered  \n",
       "topic_17  autumn equinox          sunset  \n",
       "topic_18            home        year end  \n",
       "topic_19          rising      sun bright  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model2 = NMF(20, random_state=RANDOM)\n",
    "nmf_topic2 = nmf_model2.fit_transform(haiku_train_tv2)\n",
    "pd.DataFrame(top_words(nmf_model2, tv2.get_feature_names(), 10)).add_prefix('word_').rename('topic_{}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD-IDF with bigrams seems to do much better at retrieving relevant topics. Let's try 50 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_0</th>\n",
       "      <td>rain</td>\n",
       "      <td>winter rain</td>\n",
       "      <td>spring rain</td>\n",
       "      <td>summer rain</td>\n",
       "      <td>autumn rain</td>\n",
       "      <td>night rain</td>\n",
       "      <td>smell</td>\n",
       "      <td>scent</td>\n",
       "      <td>soft</td>\n",
       "      <td>soft rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>moon</td>\n",
       "      <td>harvest</td>\n",
       "      <td>harvest moon</td>\n",
       "      <td>crescent</td>\n",
       "      <td>crescent moon</td>\n",
       "      <td>new moon</td>\n",
       "      <td>half</td>\n",
       "      <td>half moon</td>\n",
       "      <td>day moon</td>\n",
       "      <td>winter moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>thy</td>\n",
       "      <td>thou</td>\n",
       "      <td>thee</td>\n",
       "      <td>art</td>\n",
       "      <td>thou art</td>\n",
       "      <td>hast</td>\n",
       "      <td>art thou</td>\n",
       "      <td>thou hast</td>\n",
       "      <td>shalt</td>\n",
       "      <td>thine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_3</th>\n",
       "      <td>night</td>\n",
       "      <td>winter night</td>\n",
       "      <td>moonless night</td>\n",
       "      <td>moonless</td>\n",
       "      <td>starry</td>\n",
       "      <td>starry night</td>\n",
       "      <td>summer night</td>\n",
       "      <td>night rain</td>\n",
       "      <td>late night</td>\n",
       "      <td>night moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_4</th>\n",
       "      <td>day</td>\n",
       "      <td>valentine day</td>\n",
       "      <td>valentine</td>\n",
       "      <td>day day</td>\n",
       "      <td>memorial day</td>\n",
       "      <td>memorial</td>\n",
       "      <td>day moon</td>\n",
       "      <td>warm</td>\n",
       "      <td>spring day</td>\n",
       "      <td>mother day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_5</th>\n",
       "      <td>morning</td>\n",
       "      <td>fog</td>\n",
       "      <td>morning fog</td>\n",
       "      <td>morning sun</td>\n",
       "      <td>spring morning</td>\n",
       "      <td>early morning</td>\n",
       "      <td>early</td>\n",
       "      <td>winter morning</td>\n",
       "      <td>mist</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_6</th>\n",
       "      <td>summer</td>\n",
       "      <td>indian summer</td>\n",
       "      <td>indian</td>\n",
       "      <td>summer rain</td>\n",
       "      <td>heat</td>\n",
       "      <td>summer end</td>\n",
       "      <td>summer heat</td>\n",
       "      <td>summer night</td>\n",
       "      <td>late summer</td>\n",
       "      <td>solstice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_7</th>\n",
       "      <td>autumn</td>\n",
       "      <td>autumn rain</td>\n",
       "      <td>autumn wind</td>\n",
       "      <td>autumn leaves</td>\n",
       "      <td>equinox</td>\n",
       "      <td>autumn chill</td>\n",
       "      <td>autumn equinox</td>\n",
       "      <td>chill</td>\n",
       "      <td>dusk</td>\n",
       "      <td>autumn sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_8</th>\n",
       "      <td>winter</td>\n",
       "      <td>winter rain</td>\n",
       "      <td>winter night</td>\n",
       "      <td>solstice</td>\n",
       "      <td>winter solstice</td>\n",
       "      <td>deep</td>\n",
       "      <td>winter morning</td>\n",
       "      <td>deep winter</td>\n",
       "      <td>winter moon</td>\n",
       "      <td>winter stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_9</th>\n",
       "      <td>sky</td>\n",
       "      <td>blue</td>\n",
       "      <td>blue sky</td>\n",
       "      <td>color</td>\n",
       "      <td>autumn sky</td>\n",
       "      <td>winter sky</td>\n",
       "      <td>sea</td>\n",
       "      <td>sunglasses blue</td>\n",
       "      <td>eyes</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_10</th>\n",
       "      <td>old</td>\n",
       "      <td>old man</td>\n",
       "      <td>days</td>\n",
       "      <td>dog</td>\n",
       "      <td>year old</td>\n",
       "      <td>old pond</td>\n",
       "      <td>pond</td>\n",
       "      <td>old dog</td>\n",
       "      <td>wall</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_11</th>\n",
       "      <td>spring</td>\n",
       "      <td>spring rain</td>\n",
       "      <td>spring morning</td>\n",
       "      <td>spring wind</td>\n",
       "      <td>breeze</td>\n",
       "      <td>spring day</td>\n",
       "      <td>spring breeze</td>\n",
       "      <td>early spring</td>\n",
       "      <td>early</td>\n",
       "      <td>spring sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_12</th>\n",
       "      <td>love</td>\n",
       "      <td>love love</td>\n",
       "      <td>oh</td>\n",
       "      <td>song</td>\n",
       "      <td>loved</td>\n",
       "      <td>kiss</td>\n",
       "      <td>oh love</td>\n",
       "      <td>dear</td>\n",
       "      <td>true</td>\n",
       "      <td>heaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_13</th>\n",
       "      <td>light</td>\n",
       "      <td>darkness</td>\n",
       "      <td>candle</td>\n",
       "      <td>morning light</td>\n",
       "      <td>dawn</td>\n",
       "      <td>fading</td>\n",
       "      <td>eyes</td>\n",
       "      <td>light day</td>\n",
       "      <td>fading light</td>\n",
       "      <td>candle light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_14</th>\n",
       "      <td>know</td>\n",
       "      <td>did</td>\n",
       "      <td>don</td>\n",
       "      <td>did know</td>\n",
       "      <td>don know</td>\n",
       "      <td>know know</td>\n",
       "      <td>does</td>\n",
       "      <td>answer</td>\n",
       "      <td>know love</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_15</th>\n",
       "      <td>snow</td>\n",
       "      <td>fresh</td>\n",
       "      <td>falling</td>\n",
       "      <td>fresh snow</td>\n",
       "      <td>melting</td>\n",
       "      <td>falling snow</td>\n",
       "      <td>covered</td>\n",
       "      <td>snow moon</td>\n",
       "      <td>flakes</td>\n",
       "      <td>melting snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_16</th>\n",
       "      <td>come</td>\n",
       "      <td>come come</td>\n",
       "      <td>world</td>\n",
       "      <td>let</td>\n",
       "      <td>come die</td>\n",
       "      <td>die</td>\n",
       "      <td>sea</td>\n",
       "      <td>word</td>\n",
       "      <td>hear</td>\n",
       "      <td>come home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_17</th>\n",
       "      <td>wind</td>\n",
       "      <td>autumn wind</td>\n",
       "      <td>spring wind</td>\n",
       "      <td>winter wind</td>\n",
       "      <td>blowing</td>\n",
       "      <td>north</td>\n",
       "      <td>wind blowing</td>\n",
       "      <td>chill</td>\n",
       "      <td>night wind</td>\n",
       "      <td>blows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_18</th>\n",
       "      <td>new</td>\n",
       "      <td>year</td>\n",
       "      <td>new year</td>\n",
       "      <td>eve</td>\n",
       "      <td>year day</td>\n",
       "      <td>year eve</td>\n",
       "      <td>new moon</td>\n",
       "      <td>coolness</td>\n",
       "      <td>christmas</td>\n",
       "      <td>sign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_19</th>\n",
       "      <td>sun</td>\n",
       "      <td>morning sun</td>\n",
       "      <td>autumn sun</td>\n",
       "      <td>winter sun</td>\n",
       "      <td>spring sun</td>\n",
       "      <td>rising</td>\n",
       "      <td>sun bright</td>\n",
       "      <td>bright</td>\n",
       "      <td>rising sun</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_20</th>\n",
       "      <td>long</td>\n",
       "      <td>road</td>\n",
       "      <td>ago</td>\n",
       "      <td>long night</td>\n",
       "      <td>long road</td>\n",
       "      <td>long ago</td>\n",
       "      <td>long time</td>\n",
       "      <td>long long</td>\n",
       "      <td>day long</td>\n",
       "      <td>song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_21</th>\n",
       "      <td>like</td>\n",
       "      <td>world</td>\n",
       "      <td>sea</td>\n",
       "      <td>air</td>\n",
       "      <td>water</td>\n",
       "      <td>looks</td>\n",
       "      <td>tears</td>\n",
       "      <td>men</td>\n",
       "      <td>don</td>\n",
       "      <td>looks like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_22</th>\n",
       "      <td>leaves</td>\n",
       "      <td>falling</td>\n",
       "      <td>fallen</td>\n",
       "      <td>fallen leaves</td>\n",
       "      <td>falling leaves</td>\n",
       "      <td>autumn leaves</td>\n",
       "      <td>fall</td>\n",
       "      <td>maple</td>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow leaves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_23</th>\n",
       "      <td>man</td>\n",
       "      <td>old man</td>\n",
       "      <td>woman</td>\n",
       "      <td>man man</td>\n",
       "      <td>homeless man</td>\n",
       "      <td>homeless</td>\n",
       "      <td>young</td>\n",
       "      <td>young man</td>\n",
       "      <td>wife</td>\n",
       "      <td>fie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_24</th>\n",
       "      <td>white</td>\n",
       "      <td>black</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>black white</td>\n",
       "      <td>white butterfly</td>\n",
       "      <td>moonlight</td>\n",
       "      <td>white white</td>\n",
       "      <td>moth</td>\n",
       "      <td>butterflies</td>\n",
       "      <td>wings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_25</th>\n",
       "      <td>way</td>\n",
       "      <td>home</td>\n",
       "      <td>way home</td>\n",
       "      <td>milky way</td>\n",
       "      <td>milky</td>\n",
       "      <td>childhood</td>\n",
       "      <td>childhood home</td>\n",
       "      <td>look</td>\n",
       "      <td>nursing home</td>\n",
       "      <td>nursing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_26</th>\n",
       "      <td>shall</td>\n",
       "      <td>look</td>\n",
       "      <td>hear</td>\n",
       "      <td>tell</td>\n",
       "      <td>shall hear</td>\n",
       "      <td>shall look</td>\n",
       "      <td>meet</td>\n",
       "      <td>heaven</td>\n",
       "      <td>thee</td>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_27</th>\n",
       "      <td>just</td>\n",
       "      <td>ll</td>\n",
       "      <td>die</td>\n",
       "      <td>things</td>\n",
       "      <td>hear</td>\n",
       "      <td>want</td>\n",
       "      <td>moment</td>\n",
       "      <td>just moment</td>\n",
       "      <td>just wall</td>\n",
       "      <td>passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_28</th>\n",
       "      <td>cold</td>\n",
       "      <td>cup</td>\n",
       "      <td>cold night</td>\n",
       "      <td>cold rain</td>\n",
       "      <td>tea</td>\n",
       "      <td>coffee</td>\n",
       "      <td>cold snap</td>\n",
       "      <td>snap</td>\n",
       "      <td>cold morning</td>\n",
       "      <td>cold wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_29</th>\n",
       "      <td>life</td>\n",
       "      <td>death</td>\n",
       "      <td>world</td>\n",
       "      <td>oh</td>\n",
       "      <td>live</td>\n",
       "      <td>life life</td>\n",
       "      <td>soul</td>\n",
       "      <td>joy</td>\n",
       "      <td>good</td>\n",
       "      <td>years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_30</th>\n",
       "      <td>shadow</td>\n",
       "      <td>wall</td>\n",
       "      <td>shadow shadow</td>\n",
       "      <td>sun shadow</td>\n",
       "      <td>cloud</td>\n",
       "      <td>deep</td>\n",
       "      <td>stone</td>\n",
       "      <td>long shadow</td>\n",
       "      <td>earth</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_31</th>\n",
       "      <td>heart</td>\n",
       "      <td>heart heart</td>\n",
       "      <td>rest</td>\n",
       "      <td>break</td>\n",
       "      <td>eyes</td>\n",
       "      <td>care</td>\n",
       "      <td>mind</td>\n",
       "      <td>things</td>\n",
       "      <td>beat</td>\n",
       "      <td>spirit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_32</th>\n",
       "      <td>time</td>\n",
       "      <td>long time</td>\n",
       "      <td>think</td>\n",
       "      <td>read</td>\n",
       "      <td>wish</td>\n",
       "      <td>place</td>\n",
       "      <td>takes</td>\n",
       "      <td>space</td>\n",
       "      <td>space time</td>\n",
       "      <td>hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_33</th>\n",
       "      <td>end</td>\n",
       "      <td>summer end</td>\n",
       "      <td>end summer</td>\n",
       "      <td>year end</td>\n",
       "      <td>friend</td>\n",
       "      <td>year</td>\n",
       "      <td>friend end</td>\n",
       "      <td>left</td>\n",
       "      <td>dog</td>\n",
       "      <td>end day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_34</th>\n",
       "      <td>evening</td>\n",
       "      <td>fog</td>\n",
       "      <td>star</td>\n",
       "      <td>breeze</td>\n",
       "      <td>autumn evening</td>\n",
       "      <td>shadows</td>\n",
       "      <td>evening rain</td>\n",
       "      <td>dog</td>\n",
       "      <td>evening fog</td>\n",
       "      <td>summer evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_35</th>\n",
       "      <td>away</td>\n",
       "      <td>far</td>\n",
       "      <td>far away</td>\n",
       "      <td>gone</td>\n",
       "      <td>miles</td>\n",
       "      <td>ll</td>\n",
       "      <td>miles away</td>\n",
       "      <td>turned</td>\n",
       "      <td>went</td>\n",
       "      <td>takes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_36</th>\n",
       "      <td>stars</td>\n",
       "      <td>winter stars</td>\n",
       "      <td>night stars</td>\n",
       "      <td>summer stars</td>\n",
       "      <td>light stars</td>\n",
       "      <td>eyes</td>\n",
       "      <td>darkness</td>\n",
       "      <td>stars sky</td>\n",
       "      <td>faint</td>\n",
       "      <td>sun stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_37</th>\n",
       "      <td>sound</td>\n",
       "      <td>silence</td>\n",
       "      <td>sound rain</td>\n",
       "      <td>water</td>\n",
       "      <td>moon sound</td>\n",
       "      <td>sound wind</td>\n",
       "      <td>house</td>\n",
       "      <td>mouse</td>\n",
       "      <td>chimes</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_38</th>\n",
       "      <td>dead</td>\n",
       "      <td>hear</td>\n",
       "      <td>dead dead</td>\n",
       "      <td>living</td>\n",
       "      <td>earth</td>\n",
       "      <td>things</td>\n",
       "      <td>voice</td>\n",
       "      <td>heard</td>\n",
       "      <td>thought</td>\n",
       "      <td>dead leaves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_39</th>\n",
       "      <td>mother</td>\n",
       "      <td>father</td>\n",
       "      <td>mother day</td>\n",
       "      <td>child</td>\n",
       "      <td>son</td>\n",
       "      <td>daughter</td>\n",
       "      <td>holy</td>\n",
       "      <td>baby</td>\n",
       "      <td>father mother</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_40</th>\n",
       "      <td>said</td>\n",
       "      <td>word</td>\n",
       "      <td>poet</td>\n",
       "      <td>head</td>\n",
       "      <td>words</td>\n",
       "      <td>said poet</td>\n",
       "      <td>son</td>\n",
       "      <td>roses</td>\n",
       "      <td>love said</td>\n",
       "      <td>said son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_41</th>\n",
       "      <td>say</td>\n",
       "      <td>good</td>\n",
       "      <td>ll</td>\n",
       "      <td>think</td>\n",
       "      <td>did</td>\n",
       "      <td>mean</td>\n",
       "      <td>don</td>\n",
       "      <td>say good</td>\n",
       "      <td>things</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_42</th>\n",
       "      <td>tree</td>\n",
       "      <td>garden</td>\n",
       "      <td>blossoms</td>\n",
       "      <td>cherry</td>\n",
       "      <td>tree tree</td>\n",
       "      <td>storm</td>\n",
       "      <td>shade</td>\n",
       "      <td>apple</td>\n",
       "      <td>roots</td>\n",
       "      <td>cherry tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_43</th>\n",
       "      <td>window</td>\n",
       "      <td>face</td>\n",
       "      <td>open</td>\n",
       "      <td>open window</td>\n",
       "      <td>scent</td>\n",
       "      <td>house</td>\n",
       "      <td>door</td>\n",
       "      <td>look</td>\n",
       "      <td>room</td>\n",
       "      <td>outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_44</th>\n",
       "      <td>river</td>\n",
       "      <td>clouds</td>\n",
       "      <td>dark</td>\n",
       "      <td>storm</td>\n",
       "      <td>sea</td>\n",
       "      <td>water</td>\n",
       "      <td>scent</td>\n",
       "      <td>stones</td>\n",
       "      <td>ice</td>\n",
       "      <td>sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_45</th>\n",
       "      <td>god</td>\n",
       "      <td>speak</td>\n",
       "      <td>oh</td>\n",
       "      <td>let</td>\n",
       "      <td>ah</td>\n",
       "      <td>good</td>\n",
       "      <td>god speak</td>\n",
       "      <td>know god</td>\n",
       "      <td>heaven</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_46</th>\n",
       "      <td>red</td>\n",
       "      <td>blood</td>\n",
       "      <td>sunset</td>\n",
       "      <td>green</td>\n",
       "      <td>bright</td>\n",
       "      <td>blood red</td>\n",
       "      <td>line</td>\n",
       "      <td>leaf</td>\n",
       "      <td>gold</td>\n",
       "      <td>bright red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_47</th>\n",
       "      <td>late</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>late summer</td>\n",
       "      <td>late night</td>\n",
       "      <td>late winter</td>\n",
       "      <td>late afternoon</td>\n",
       "      <td>late autumn</td>\n",
       "      <td>soon</td>\n",
       "      <td>house</td>\n",
       "      <td>waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_48</th>\n",
       "      <td>hand</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>hand hand</td>\n",
       "      <td>heat</td>\n",
       "      <td>prec</td>\n",
       "      <td>walk</td>\n",
       "      <td>small</td>\n",
       "      <td>eye</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_49</th>\n",
       "      <td>little</td>\n",
       "      <td>boy</td>\n",
       "      <td>little boy</td>\n",
       "      <td>let</td>\n",
       "      <td>good</td>\n",
       "      <td>think</td>\n",
       "      <td>girl</td>\n",
       "      <td>children</td>\n",
       "      <td>child</td>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_0         word_1          word_2         word_3  \\\n",
       "topic_0      rain    winter rain     spring rain    summer rain   \n",
       "topic_1      moon        harvest    harvest moon       crescent   \n",
       "topic_2       thy           thou            thee            art   \n",
       "topic_3     night   winter night  moonless night       moonless   \n",
       "topic_4       day  valentine day       valentine        day day   \n",
       "topic_5   morning            fog     morning fog    morning sun   \n",
       "topic_6    summer  indian summer          indian    summer rain   \n",
       "topic_7    autumn    autumn rain     autumn wind  autumn leaves   \n",
       "topic_8    winter    winter rain    winter night       solstice   \n",
       "topic_9       sky           blue        blue sky          color   \n",
       "topic_10      old        old man            days            dog   \n",
       "topic_11   spring    spring rain  spring morning    spring wind   \n",
       "topic_12     love      love love              oh           song   \n",
       "topic_13    light       darkness          candle  morning light   \n",
       "topic_14     know            did             don       did know   \n",
       "topic_15     snow          fresh         falling     fresh snow   \n",
       "topic_16     come      come come           world            let   \n",
       "topic_17     wind    autumn wind     spring wind    winter wind   \n",
       "topic_18      new           year        new year            eve   \n",
       "topic_19      sun    morning sun      autumn sun     winter sun   \n",
       "topic_20     long           road             ago     long night   \n",
       "topic_21     like          world             sea            air   \n",
       "topic_22   leaves        falling          fallen  fallen leaves   \n",
       "topic_23      man        old man           woman        man man   \n",
       "topic_24    white          black       butterfly    black white   \n",
       "topic_25      way           home        way home      milky way   \n",
       "topic_26    shall           look            hear           tell   \n",
       "topic_27     just             ll             die         things   \n",
       "topic_28     cold            cup      cold night      cold rain   \n",
       "topic_29     life          death           world             oh   \n",
       "topic_30   shadow           wall   shadow shadow     sun shadow   \n",
       "topic_31    heart    heart heart            rest          break   \n",
       "topic_32     time      long time           think           read   \n",
       "topic_33      end     summer end      end summer       year end   \n",
       "topic_34  evening            fog            star         breeze   \n",
       "topic_35     away            far        far away           gone   \n",
       "topic_36    stars   winter stars     night stars   summer stars   \n",
       "topic_37    sound        silence      sound rain          water   \n",
       "topic_38     dead           hear       dead dead         living   \n",
       "topic_39   mother         father      mother day          child   \n",
       "topic_40     said           word            poet           head   \n",
       "topic_41      say           good              ll          think   \n",
       "topic_42     tree         garden        blossoms         cherry   \n",
       "topic_43   window           face            open    open window   \n",
       "topic_44    river         clouds            dark          storm   \n",
       "topic_45      god          speak              oh            let   \n",
       "topic_46      red          blood          sunset          green   \n",
       "topic_47     late      afternoon     late summer     late night   \n",
       "topic_48     hand           left           right      hand hand   \n",
       "topic_49   little            boy      little boy            let   \n",
       "\n",
       "                   word_4          word_5          word_6           word_7  \\\n",
       "topic_0       autumn rain      night rain           smell            scent   \n",
       "topic_1     crescent moon        new moon            half        half moon   \n",
       "topic_2          thou art            hast        art thou        thou hast   \n",
       "topic_3            starry    starry night    summer night       night rain   \n",
       "topic_4      memorial day        memorial        day moon             warm   \n",
       "topic_5    spring morning   early morning           early   winter morning   \n",
       "topic_6              heat      summer end     summer heat     summer night   \n",
       "topic_7           equinox    autumn chill  autumn equinox            chill   \n",
       "topic_8   winter solstice            deep  winter morning      deep winter   \n",
       "topic_9        autumn sky      winter sky             sea  sunglasses blue   \n",
       "topic_10         year old        old pond            pond          old dog   \n",
       "topic_11           breeze      spring day   spring breeze     early spring   \n",
       "topic_12            loved            kiss         oh love             dear   \n",
       "topic_13             dawn          fading            eyes        light day   \n",
       "topic_14         don know       know know            does           answer   \n",
       "topic_15          melting    falling snow         covered        snow moon   \n",
       "topic_16         come die             die             sea             word   \n",
       "topic_17          blowing           north    wind blowing            chill   \n",
       "topic_18         year day        year eve        new moon         coolness   \n",
       "topic_19       spring sun          rising      sun bright           bright   \n",
       "topic_20        long road        long ago       long time        long long   \n",
       "topic_21            water           looks           tears              men   \n",
       "topic_22   falling leaves   autumn leaves            fall            maple   \n",
       "topic_23     homeless man        homeless           young        young man   \n",
       "topic_24  white butterfly       moonlight     white white             moth   \n",
       "topic_25            milky       childhood  childhood home             look   \n",
       "topic_26       shall hear      shall look            meet           heaven   \n",
       "topic_27             hear            want          moment      just moment   \n",
       "topic_28              tea          coffee       cold snap             snap   \n",
       "topic_29             live       life life            soul              joy   \n",
       "topic_30            cloud            deep           stone      long shadow   \n",
       "topic_31             eyes            care            mind           things   \n",
       "topic_32             wish           place           takes            space   \n",
       "topic_33           friend            year      friend end             left   \n",
       "topic_34   autumn evening         shadows    evening rain              dog   \n",
       "topic_35            miles              ll      miles away           turned   \n",
       "topic_36      light stars            eyes        darkness        stars sky   \n",
       "topic_37       moon sound      sound wind           house            mouse   \n",
       "topic_38            earth          things           voice            heard   \n",
       "topic_39              son        daughter            holy             baby   \n",
       "topic_40            words       said poet             son            roses   \n",
       "topic_41              did            mean             don         say good   \n",
       "topic_42        tree tree           storm           shade            apple   \n",
       "topic_43            scent           house            door             look   \n",
       "topic_44              sea           water           scent           stones   \n",
       "topic_45               ah            good       god speak         know god   \n",
       "topic_46           bright       blood red            line             leaf   \n",
       "topic_47      late winter  late afternoon     late autumn             soon   \n",
       "topic_48             heat            prec            walk            small   \n",
       "topic_49             good           think            girl         children   \n",
       "\n",
       "                 word_8          word_9  \n",
       "topic_0            soft       soft rain  \n",
       "topic_1        day moon     winter moon  \n",
       "topic_2           shalt           thine  \n",
       "topic_3      late night      night moon  \n",
       "topic_4      spring day      mother day  \n",
       "topic_5            mist          coffee  \n",
       "topic_6     late summer        solstice  \n",
       "topic_7            dusk      autumn sun  \n",
       "topic_8     winter moon    winter stars  \n",
       "topic_9            eyes           clear  \n",
       "topic_10           wall             men  \n",
       "topic_11          early      spring sun  \n",
       "topic_12           true          heaven  \n",
       "topic_13   fading light    candle light  \n",
       "topic_14      know love           think  \n",
       "topic_15         flakes    melting snow  \n",
       "topic_16           hear       come home  \n",
       "topic_17     night wind           blows  \n",
       "topic_18      christmas            sign  \n",
       "topic_19     rising sun             low  \n",
       "topic_20       day long            song  \n",
       "topic_21            don      looks like  \n",
       "topic_22         yellow   yellow leaves  \n",
       "topic_23           wife             fie  \n",
       "topic_24    butterflies           wings  \n",
       "topic_25   nursing home         nursing  \n",
       "topic_26           thee            feel  \n",
       "topic_27      just wall         passing  \n",
       "topic_28   cold morning       cold wind  \n",
       "topic_29           good           years  \n",
       "topic_30          earth           black  \n",
       "topic_31           beat          spirit  \n",
       "topic_32     space time           hands  \n",
       "topic_33            dog         end day  \n",
       "topic_34    evening fog  summer evening  \n",
       "topic_35           went           takes  \n",
       "topic_36          faint       sun stars  \n",
       "topic_37         chimes            door  \n",
       "topic_38        thought     dead leaves  \n",
       "topic_39  father mother           young  \n",
       "topic_40      love said        said son  \n",
       "topic_41         things          people  \n",
       "topic_42          roots     cherry tree  \n",
       "topic_43           room         outside  \n",
       "topic_44            ice          sunset  \n",
       "topic_45         heaven           truth  \n",
       "topic_46           gold      bright red  \n",
       "topic_47          house         waiting  \n",
       "topic_48            eye            land  \n",
       "topic_49          child            baby  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model2 = NMF(50, random_state=RANDOM)\n",
    "nmf_topic2 = nmf_model2.fit_transform(haiku_train_tv2)\n",
    "nmf_50topics_details = pd.DataFrame(top_words(nmf_model2, tv2.get_feature_names(), 10))\\\n",
    "                        .add_prefix('word_').rename('topic_{}'.format)\n",
    "\n",
    "nmf_50topics_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 50 topics also seem pretty decent, let's go with that for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_40</th>\n",
       "      <th>topic_41</th>\n",
       "      <th>topic_42</th>\n",
       "      <th>topic_43</th>\n",
       "      <th>topic_44</th>\n",
       "      <th>topic_45</th>\n",
       "      <th>topic_46</th>\n",
       "      <th>topic_47</th>\n",
       "      <th>topic_48</th>\n",
       "      <th>topic_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.689159e-07</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12344</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12027</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.272065e-04</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>9.253097e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23119</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010232</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.071436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>2.787117e-04</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.075547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.242980e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25128 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic_0   topic_1       topic_2   topic_3   topic_4   topic_5  \\\n",
       "3609   0.000005  0.000000  4.689159e-07  0.000637  0.000321  0.000000   \n",
       "12344  0.000000  0.000000  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "12027  0.000017  0.000000  2.272065e-04  0.000531  0.000070  0.000036   \n",
       "4696   0.000020  0.000017  9.253097e-05  0.000000  0.001024  0.000101   \n",
       "23119  0.000000  0.000000  0.000000e+00  0.000000  0.000000  0.010232   \n",
       "...         ...       ...           ...       ...       ...       ...   \n",
       "29802  0.000022  0.000124  2.787117e-04  0.000549  0.000469  0.000000   \n",
       "5390   0.000000  0.000973  0.000000e+00  0.000000  0.000191  0.000138   \n",
       "860    0.000000  0.000000  0.000000e+00  0.000702  0.075547  0.000000   \n",
       "15795  0.000041  0.000000  0.000000e+00  0.000000  0.046239  0.000000   \n",
       "23654  0.000000  0.000000  5.242980e-04  0.000000  0.000000  0.000305   \n",
       "\n",
       "        topic_6   topic_7   topic_8   topic_9  ...  topic_40  topic_41  \\\n",
       "3609   0.000162  0.000343  0.001079  0.000000  ...  0.000474  0.000307   \n",
       "12344  0.000000  0.000000  0.000000  0.000000  ...  0.000007  0.000051   \n",
       "12027  0.000000  0.000331  0.000000  0.000000  ...  0.002775  0.000000   \n",
       "4696   0.002012  0.000199  0.000000  0.000000  ...  0.000154  0.000000   \n",
       "23119  0.000129  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "29802  0.000184  0.000210  0.000104  0.001658  ...  0.001719  0.001038   \n",
       "5390   0.000000  0.000450  0.000000  0.000000  ...  0.000075  0.000461   \n",
       "860    0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "15795  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000527   \n",
       "23654  0.000235  0.000000  0.000012  0.000827  ...  0.000000  0.000000   \n",
       "\n",
       "       topic_42  topic_43  topic_44  topic_45  topic_46  topic_47  topic_48  \\\n",
       "3609   0.000000  0.000717  0.000000  0.001847  0.000000  0.000654  0.000891   \n",
       "12344  0.000000  0.000000  0.000000  0.000011  0.000000  0.000010  0.000000   \n",
       "12027  0.001250  0.000812  0.000000  0.003113  0.000000  0.000797  0.002742   \n",
       "4696   0.000864  0.000000  0.000235  0.000000  0.000000  0.000254  0.000000   \n",
       "23119  0.000000  0.002015  0.071436  0.000000  0.006212  0.000047  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29802  0.002611  0.008232  0.000459  0.000929  0.000000  0.002618  0.000000   \n",
       "5390   0.000000  0.000188  0.001418  0.000000  0.004348  0.000000  0.000829   \n",
       "860    0.000000  0.000000  0.026900  0.000000  0.000000  0.000000  0.000000   \n",
       "15795  0.000000  0.000000  0.000000  0.000412  0.000000  0.000000  0.000000   \n",
       "23654  0.005813  0.003027  0.000000  0.000000  0.000652  0.000000  0.000000   \n",
       "\n",
       "       topic_49  \n",
       "3609   0.002135  \n",
       "12344  0.000011  \n",
       "12027  0.002847  \n",
       "4696   0.000000  \n",
       "23119  0.000000  \n",
       "...         ...  \n",
       "29802  0.000572  \n",
       "5390   0.001437  \n",
       "860    0.000000  \n",
       "15795  0.001214  \n",
       "23654  0.000140  \n",
       "\n",
       "[25128 rows x 50 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_50topics = pd.DataFrame(nmf_topic2, index=haikus_train_df.index).add_prefix('topic_')\n",
    "\n",
    "nmf_50topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29340"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_50topics.max(axis=1).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_24    0.000000e+00\n",
       "topic_27    0.000000e+00\n",
       "topic_29    0.000000e+00\n",
       "topic_15    0.000000e+00\n",
       "topic_14    0.000000e+00\n",
       "topic_13    0.000000e+00\n",
       "topic_12    0.000000e+00\n",
       "topic_30    0.000000e+00\n",
       "topic_31    0.000000e+00\n",
       "topic_9     0.000000e+00\n",
       "topic_37    0.000000e+00\n",
       "topic_38    0.000000e+00\n",
       "topic_42    0.000000e+00\n",
       "topic_5     0.000000e+00\n",
       "topic_44    0.000000e+00\n",
       "topic_46    0.000000e+00\n",
       "topic_1     0.000000e+00\n",
       "topic_25    0.000000e+00\n",
       "topic_23    0.000000e+00\n",
       "topic_2     4.689159e-07\n",
       "topic_0     5.198011e-06\n",
       "topic_10    2.118179e-05\n",
       "topic_17    3.430456e-05\n",
       "topic_32    4.741704e-05\n",
       "topic_35    8.872725e-05\n",
       "topic_20    9.973198e-05\n",
       "topic_22    1.142687e-04\n",
       "topic_6     1.621451e-04\n",
       "topic_16    2.432271e-04\n",
       "topic_28    2.938739e-04\n",
       "topic_41    3.071341e-04\n",
       "topic_4     3.211737e-04\n",
       "topic_7     3.433245e-04\n",
       "topic_34    3.635730e-04\n",
       "topic_19    3.867972e-04\n",
       "topic_11    4.250823e-04\n",
       "topic_40    4.744653e-04\n",
       "topic_3     6.369079e-04\n",
       "topic_47    6.537482e-04\n",
       "topic_43    7.174449e-04\n",
       "topic_26    8.233320e-04\n",
       "topic_39    8.315352e-04\n",
       "topic_48    8.912185e-04\n",
       "topic_33    9.875664e-04\n",
       "topic_36    9.964459e-04\n",
       "topic_8     1.078831e-03\n",
       "topic_18    1.173099e-03\n",
       "topic_45    1.846819e-03\n",
       "topic_21    1.848918e-03\n",
       "topic_49    2.134741e-03\n",
       "Name: 3609, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_50topics.iloc[0].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3609     topic_49\n",
       "12344    topic_10\n",
       "12027    topic_31\n",
       "4696     topic_11\n",
       "23119    topic_44\n",
       "           ...   \n",
       "29802    topic_43\n",
       "5390     topic_46\n",
       "860       topic_4\n",
       "15795    topic_37\n",
       "23654    topic_21\n",
       "Length: 25128, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_50topics.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                  And I\n",
       " 1    shall have nothing,\n",
       " 2               nothing!\n",
       " Name: 29340, dtype: object,\n",
       " word_0         shall\n",
       " word_1          look\n",
       " word_2          hear\n",
       " word_3          tell\n",
       " word_4    shall hear\n",
       " word_5    shall look\n",
       " word_6          meet\n",
       " word_7        heaven\n",
       " word_8          thee\n",
       " word_9          feel\n",
       " Name: topic_26, dtype: object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haikus_train_df.loc[29340][line_cols], nmf_50topics_details.loc[nmf_50topics.loc[29340].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. With GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "glove_file = './data/image_to_text/glove.840B.300d.txt'\n",
    "tmp_file = './data/image_to_text/glovetmp.txt'\n",
    "\n",
    "if not os.path.isfile(tmp_file):\n",
    "    _ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(text, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += glove_model[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku_glove_train = haikus_train_df['text'].apply(lambda s: buildWordVector(s.split(' '), 300)[0])\n",
    "haiku_glove_test = haikus_test_df['text'].apply(lambda s: buildWordVector(s.split(' '), 300)[0])\n",
    "\n",
    "haiku_glove_train_df = pd.DataFrame(list(haiku_glove_train), index=haikus_train_df.index).add_prefix('glove_')\n",
    "haiku_glove_test_df = pd.DataFrame(list(haiku_glove_test), index=haikus_test_df.index).add_prefix('glove_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glove_0</th>\n",
       "      <th>glove_1</th>\n",
       "      <th>glove_2</th>\n",
       "      <th>glove_3</th>\n",
       "      <th>glove_4</th>\n",
       "      <th>glove_5</th>\n",
       "      <th>glove_6</th>\n",
       "      <th>glove_7</th>\n",
       "      <th>glove_8</th>\n",
       "      <th>glove_9</th>\n",
       "      <th>...</th>\n",
       "      <th>glove_290</th>\n",
       "      <th>glove_291</th>\n",
       "      <th>glove_292</th>\n",
       "      <th>glove_293</th>\n",
       "      <th>glove_294</th>\n",
       "      <th>glove_295</th>\n",
       "      <th>glove_296</th>\n",
       "      <th>glove_297</th>\n",
       "      <th>glove_298</th>\n",
       "      <th>glove_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.144642</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>-0.004059</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.092235</td>\n",
       "      <td>-0.164611</td>\n",
       "      <td>0.078713</td>\n",
       "      <td>-0.024613</td>\n",
       "      <td>1.892366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122115</td>\n",
       "      <td>0.027652</td>\n",
       "      <td>-0.111866</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>-0.054992</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.133955</td>\n",
       "      <td>-0.090081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12344</th>\n",
       "      <td>-0.082213</td>\n",
       "      <td>0.056645</td>\n",
       "      <td>0.127280</td>\n",
       "      <td>-0.330566</td>\n",
       "      <td>0.092171</td>\n",
       "      <td>-0.079778</td>\n",
       "      <td>0.543255</td>\n",
       "      <td>0.101867</td>\n",
       "      <td>-0.110720</td>\n",
       "      <td>-0.493580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098641</td>\n",
       "      <td>-0.404362</td>\n",
       "      <td>-0.269700</td>\n",
       "      <td>0.061225</td>\n",
       "      <td>0.083722</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>-0.152077</td>\n",
       "      <td>0.341448</td>\n",
       "      <td>-0.216030</td>\n",
       "      <td>0.013653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12027</th>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.096822</td>\n",
       "      <td>-0.164946</td>\n",
       "      <td>-0.067310</td>\n",
       "      <td>0.060695</td>\n",
       "      <td>-0.049959</td>\n",
       "      <td>0.068478</td>\n",
       "      <td>-0.109064</td>\n",
       "      <td>-0.026961</td>\n",
       "      <td>2.684088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323211</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>-0.018777</td>\n",
       "      <td>0.040273</td>\n",
       "      <td>0.065825</td>\n",
       "      <td>-0.032649</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.043149</td>\n",
       "      <td>0.038904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.186946</td>\n",
       "      <td>-0.182676</td>\n",
       "      <td>-0.076836</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>-0.110118</td>\n",
       "      <td>-0.147122</td>\n",
       "      <td>0.084796</td>\n",
       "      <td>-0.007867</td>\n",
       "      <td>1.575796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242630</td>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.209571</td>\n",
       "      <td>-0.152839</td>\n",
       "      <td>-0.078191</td>\n",
       "      <td>0.091482</td>\n",
       "      <td>0.174094</td>\n",
       "      <td>0.071815</td>\n",
       "      <td>-0.273848</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23119</th>\n",
       "      <td>0.151909</td>\n",
       "      <td>0.088393</td>\n",
       "      <td>-0.025562</td>\n",
       "      <td>-0.032305</td>\n",
       "      <td>0.238123</td>\n",
       "      <td>0.107035</td>\n",
       "      <td>-0.058097</td>\n",
       "      <td>0.050178</td>\n",
       "      <td>-0.090315</td>\n",
       "      <td>1.781929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144367</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.072155</td>\n",
       "      <td>-0.245300</td>\n",
       "      <td>-0.110313</td>\n",
       "      <td>-0.028663</td>\n",
       "      <td>0.047038</td>\n",
       "      <td>0.106898</td>\n",
       "      <td>-0.280544</td>\n",
       "      <td>-0.096316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>0.063456</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>-0.226104</td>\n",
       "      <td>-0.085388</td>\n",
       "      <td>0.115210</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>-0.030782</td>\n",
       "      <td>-0.143396</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>2.057132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335843</td>\n",
       "      <td>-0.036722</td>\n",
       "      <td>0.036782</td>\n",
       "      <td>0.100949</td>\n",
       "      <td>-0.040385</td>\n",
       "      <td>0.115409</td>\n",
       "      <td>0.174129</td>\n",
       "      <td>0.024463</td>\n",
       "      <td>0.125788</td>\n",
       "      <td>0.020009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>-0.025521</td>\n",
       "      <td>-0.070567</td>\n",
       "      <td>-0.223037</td>\n",
       "      <td>-0.148321</td>\n",
       "      <td>-0.067061</td>\n",
       "      <td>-0.064510</td>\n",
       "      <td>0.051353</td>\n",
       "      <td>-0.084710</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>1.630664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140885</td>\n",
       "      <td>0.130814</td>\n",
       "      <td>0.046790</td>\n",
       "      <td>-0.225410</td>\n",
       "      <td>-0.060154</td>\n",
       "      <td>-0.077138</td>\n",
       "      <td>-0.100798</td>\n",
       "      <td>-0.041543</td>\n",
       "      <td>0.210341</td>\n",
       "      <td>0.107860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.055426</td>\n",
       "      <td>0.206669</td>\n",
       "      <td>-0.029647</td>\n",
       "      <td>-0.125029</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>-0.148260</td>\n",
       "      <td>-0.244038</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>1.701388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270555</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.138867</td>\n",
       "      <td>-0.312291</td>\n",
       "      <td>-0.250849</td>\n",
       "      <td>0.078958</td>\n",
       "      <td>0.095515</td>\n",
       "      <td>-0.017021</td>\n",
       "      <td>-0.011959</td>\n",
       "      <td>0.131399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0.101601</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>-0.073208</td>\n",
       "      <td>-0.027221</td>\n",
       "      <td>0.133731</td>\n",
       "      <td>-0.048321</td>\n",
       "      <td>-0.122075</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.027139</td>\n",
       "      <td>2.233458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361302</td>\n",
       "      <td>-0.053324</td>\n",
       "      <td>-0.009555</td>\n",
       "      <td>-0.090044</td>\n",
       "      <td>-0.039933</td>\n",
       "      <td>0.109818</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>0.013973</td>\n",
       "      <td>0.029866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>0.263166</td>\n",
       "      <td>0.151848</td>\n",
       "      <td>0.115960</td>\n",
       "      <td>0.102065</td>\n",
       "      <td>0.198851</td>\n",
       "      <td>0.153375</td>\n",
       "      <td>-0.108486</td>\n",
       "      <td>0.186636</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>1.740064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143559</td>\n",
       "      <td>0.185735</td>\n",
       "      <td>0.196605</td>\n",
       "      <td>-0.174699</td>\n",
       "      <td>-0.090582</td>\n",
       "      <td>0.157651</td>\n",
       "      <td>0.072868</td>\n",
       "      <td>0.172157</td>\n",
       "      <td>-0.172938</td>\n",
       "      <td>0.349628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25128 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        glove_0   glove_1   glove_2   glove_3   glove_4   glove_5   glove_6  \\\n",
       "3609   0.071281  0.144642  0.040427 -0.004059  0.278126  0.092235 -0.164611   \n",
       "12344 -0.082213  0.056645  0.127280 -0.330566  0.092171 -0.079778  0.543255   \n",
       "12027  0.021070  0.096822 -0.164946 -0.067310  0.060695 -0.049959  0.068478   \n",
       "4696   0.151458  0.186946 -0.182676 -0.076836  0.059533 -0.110118 -0.147122   \n",
       "23119  0.151909  0.088393 -0.025562 -0.032305  0.238123  0.107035 -0.058097   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29802  0.063456  0.065163 -0.226104 -0.085388  0.115210 -0.057175 -0.030782   \n",
       "5390  -0.025521 -0.070567 -0.223037 -0.148321 -0.067061 -0.064510  0.051353   \n",
       "860    0.055426  0.206669 -0.029647 -0.125029  0.031141 -0.148260 -0.244038   \n",
       "15795  0.101601  0.110988 -0.073208 -0.027221  0.133731 -0.048321 -0.122075   \n",
       "23654  0.263166  0.151848  0.115960  0.102065  0.198851  0.153375 -0.108486   \n",
       "\n",
       "        glove_7   glove_8   glove_9  ...  glove_290  glove_291  glove_292  \\\n",
       "3609   0.078713 -0.024613  1.892366  ...  -0.122115   0.027652  -0.111866   \n",
       "12344  0.101867 -0.110720 -0.493580  ...   0.098641  -0.404362  -0.269700   \n",
       "12027 -0.109064 -0.026961  2.684088  ...  -0.323211   0.020446  -0.003793   \n",
       "4696   0.084796 -0.007867  1.575796  ...  -0.242630   0.029339   0.209571   \n",
       "23119  0.050178 -0.090315  1.781929  ...  -0.144367   0.011191   0.072155   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "29802 -0.143396  0.019982  2.057132  ...  -0.335843  -0.036722   0.036782   \n",
       "5390  -0.084710  0.003703  1.630664  ...  -0.140885   0.130814   0.046790   \n",
       "860    0.144470 -0.002504  1.701388  ...  -0.270555   0.079200   0.138867   \n",
       "15795  0.060302  0.027139  2.233458  ...  -0.361302  -0.053324  -0.009555   \n",
       "23654  0.186636  0.023104  1.740064  ...  -0.143559   0.185735   0.196605   \n",
       "\n",
       "       glove_293  glove_294  glove_295  glove_296  glove_297  glove_298  \\\n",
       "3609   -0.058247  -0.054992   0.061078   0.093764  -0.007376  -0.133955   \n",
       "12344   0.061225   0.083722   0.011395  -0.152077   0.341448  -0.216030   \n",
       "12027  -0.018777   0.040273   0.065825  -0.032649   0.066116   0.043149   \n",
       "4696   -0.152839  -0.078191   0.091482   0.174094   0.071815  -0.273848   \n",
       "23119  -0.245300  -0.110313  -0.028663   0.047038   0.106898  -0.280544   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29802   0.100949  -0.040385   0.115409   0.174129   0.024463   0.125788   \n",
       "5390   -0.225410  -0.060154  -0.077138  -0.100798  -0.041543   0.210341   \n",
       "860    -0.312291  -0.250849   0.078958   0.095515  -0.017021  -0.011959   \n",
       "15795  -0.090044  -0.039933   0.109818  -0.055122   0.027885   0.013973   \n",
       "23654  -0.174699  -0.090582   0.157651   0.072868   0.172157  -0.172938   \n",
       "\n",
       "       glove_299  \n",
       "3609   -0.090081  \n",
       "12344   0.013653  \n",
       "12027   0.038904  \n",
       "4696    0.003690  \n",
       "23119  -0.096316  \n",
       "...          ...  \n",
       "29802   0.020009  \n",
       "5390    0.107860  \n",
       "860     0.131399  \n",
       "15795   0.029866  \n",
       "23654   0.349628  \n",
       "\n",
       "[25128 rows x 300 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku_glove_train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
